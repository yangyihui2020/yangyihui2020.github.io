<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>hexo+vscode实现快速图片插入</title>
    <link href="/2025/04/11/essays/Hexo/hexo%E5%BF%AB%E9%80%9F%E5%9B%BE%E7%89%87%E6%8F%92%E5%85%A5/"/>
    <url>/2025/04/11/essays/Hexo/hexo%E5%BF%AB%E9%80%9F%E5%9B%BE%E7%89%87%E6%8F%92%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<p>我们通常使用hexo框架插入图片时，图片通常会被保存到一个绝对路径的文件夹下<code>\source\images</code>, 这样比较麻烦，这里介绍一种可以直接在插入保存到粘贴板中的方法。</p><h4 id="首先使用hexo-new命令来创建文章比如我使用">首先使用<code>hexo new</code>命令来创建文章，比如我使用</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">hexo <span class="hljs-keyword">new</span> post hexo+vscode实现快速图片插入 -p essays<span class="hljs-regexp">/Hexo/</span>hexo快速图片插入<br></code></pre></td></tr></table></figure><p>该命令会新建一个md文件和与md文件同名的文件夹，我们就可以使用该文件夹来储存图片。</p><h4 id="然后在扩展中新增paste-image插件同时在vscode-的settings.json新加配置">然后在扩展中新增paste image插件，同时在vscode 的settings.json新加配置:</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-string">&quot;pasteImage.path&quot;</span>: <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;currentFileDir&#125;</span>/<span class="hljs-variable">$&#123;currentFileNameWithoutExt&#125;</span>&quot;</span> <br><br></code></pre></td></tr></table></figure><h4 id="然后使用快捷键ctrl-alt-v就可以快速保存图片并且插入图片url">然后使用快捷键ctrl-alt-v就可以快速保存图片并且插入图片url。</h4><p><img src="2025-04-11-17-18-08.png" /></p>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo新建文章到指定目录的方式</title>
    <link href="/2025/04/11/essays/Hexo/hexo%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95/"/>
    <url>/2025/04/11/essays/Hexo/hexo%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>使用 -p参数指定文章生成的路径</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">hexo <span class="hljs-keyword">new</span> post hexo新建文章到指定目录的方式 -p essays<span class="hljs-regexp">/Hexo/</span>hexo新建文章到指定目录<br></code></pre></td></tr></table></figure><p>上述命令，会在<code>\source\_posts\essays\Hexo</code>目录下新建一个<code>hexo新建文章到指定目录.md</code>文件，对应的文章标题为hexo新建文章到指定目录的方式</p>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>test</title>
    <link href="/2025/04/11/project/test1/"/>
    <url>/2025/04/11/project/test1/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CogLTX-Applting BERT to LOng Texts 论文阅读 And 大模型编码梳理</title>
    <link href="/2025/04/11/ReadingNotes/rag/CogLTX-Applting%20BERT%20to%20LOng%20Texts%20And%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BC%96%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <url>/2025/04/11/ReadingNotes/rag/CogLTX-Applting%20BERT%20to%20LOng%20Texts%20And%20%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BC%96%E7%A0%81%E6%A2%B3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="大模型编码梳理">大模型编码梳理</h2><p>本文将以Transformer模型为例，梳理大模型生成嵌入的思路。</p><p>计算机无法直接理解人类语言。它们需要将文本以数字形式表示——使用向量、矩阵或数字序列。这种转换使得像Transformer这样的模型能够处理数据并从中学习。以Transformer为代表的模型通常生成嵌入的思路如下：</p><h2 id="一输入处理">一、输入处理</h2><p>使用任何机器学习模型的第一步都是处理输入数据。加入我们现在有这样一个输入文本是： <figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">“生活就像骑自行车。”<br></code></pre></td></tr></table></figure></p><h3 id="一构建词汇表">（一）构建词汇表</h3><p>在处理文本之前，需要创建一个词汇表——一个包含训练数据集中每个单词的字典。例如，如果我们的训练数据包含各种励志名言，我们的词汇表可能包括“生活”、“平衡”、“自行车”、“前行”等词汇。每个单词都映射到一个唯一的索引。因此，训练数据中所有不重复的单词将组成词汇表。</p><h3 id="二分配数字索引">（二）分配数字索引</h3><p>接下来，我们为词汇表中的每个单词分配一个唯一的数字索引。这样，我们就可以用数字来表示单词了。</p><h3 id="三提取输入单词">（三）提取输入单词</h3><p>对于输入文本“Life is like riding a bicycle”，我们提取相应的索引如下，</p><h3 id="四转换成序列">（四）转换成序列</h3><p>这一系列的索引就是输入到Transformer模型中的数据。它作为输入文本的数值表示，使模型能够对其进行处理。</p><h2 id="二词嵌入">二、词嵌入</h2><p>一旦我们有了输入序列的索引，下一步就是将这些索引转换成词嵌入。词嵌入将每个单词表示为固定大小的向量，使得模型更容易捕捉单词之间的语义关系。</p><h3 id="一什么是词嵌入">（一）什么是词嵌入？</h3><p>词嵌入是编码单词语义信息的高维向量，相似的单词或经常同时出现的单词具有相似的嵌入。这些向量可以想象成一个多维空间（通常是数百个维度，如原始Transformer论文中的512维），在这个空间中，由于上下文相似，“bicycle”（自行车）和“ride”（骑行）之间的距离比“bicycle”（自行车）和“cloud”（云）之间的距离更近。嵌入的每个维度都捕捉了某些语言特征，比如一个单词是动词还是实体。然而，由于这些特征是在训练过程中学习的，因此确定每个维度的确切含义可能具有挑战性。</p><h3 id="二嵌入层">（二）嵌入层</h3><p>我们序列中的每个词索引都会通过一个嵌入层。这个层将每个索引映射到一个实数向量。原始的Transformer论文中使用的嵌入大小为512。</p><h3 id="三学习有意义的表征">（三）学习有意义的表征</h3><p>最初，这些嵌入是随机分配的。在训练过程中，Transformer会根据给定的任务调整这些向量，以更好地表示单词的含义。例如，“life”（生命）和“existence”（存在）的嵌入可能会随着时间的推移而变得更加接近，因为它们具有相似的含义。</p><h3 id="四嵌入的可视化">（四）嵌入的可视化</h3><p>想象一下在多维空间中绘制单词。像“life”（生命）、“alive”（活着的）和“survival”（生存）这样的单词会聚集在一起，而像“bicycle”（自行车）和“cloud”（云）这样的单词则会相距较远。</p><p>这有助于Transformer不仅理解单个单词，还能理解它们在给定上下文中的相互关系。嵌入层有助于将原始数值输入转换为Transformer可以用来理解文本的丰富表征。</p><h2 id="三位置嵌入">三、位置嵌入</h2><p>现在我们已经有了词嵌入，接下来需要解决一个关键问题——Transformer天生并不理解单词的顺序。与像LSTM这样的循环模型逐个处理序列中的单词不同，Transformer会同时查看所有单词。虽然这使得它们更快，但也意味着它们缺乏单词出现顺序的信息。</p><p>考虑以下两个句子：</p><p><em>“Life is like riding a bicycle, it requires balance.”（生活就像骑自行车，它需要平衡。）</em></p><p><em>“Life requires balance, like riding a bicycle.”（生活需要平衡，就像骑自行车一样。）</em></p><p>这两个句子包含相同的单词，但结构略有不同，导致意义上有细微差别。为了让Transformer捕捉到这些差异，我们需要添加关于单词顺序的信息——这就是位置嵌入发挥作用的地方。</p><h3 id="一方法1基于整数的位置编码">（一）方法1：基于整数的位置编码</h3><p>一个直接的想法是给每个位置分配一个对应的整数。例如，第一个词的嵌入会携带一个全零向量，下一个词则是一个全一向量，依此类推。然而，这种方法很快就会暴露出局限性。随着序列长度的增加，分配给后续单词的较大数字可能会压过底层的词嵌入，导致表示发生偏斜。这种不对齐可能会影响模型保持语义一致性的能力，尤其是在较长文本中。</p><h3 id="二方法2相对于序列长度的分数位置表示">（二）方法2：相对于序列长度的分数位置表示</h3><p>另一种直观的方法是将每个单词的位置表示为总序列长度的一个分数，确保值在0到1之间保持归一化。例如，在一个包含四个单词的句子中，位置嵌入可能对应于像0.25、0.5这样的值。</p><p>这一策略虽然看似有效，但却引入了一个重大挑战：相同位置（例如，第二个单词p1）的位置嵌入会因序列长度的不同而变化，从而引入不一致性，这可能会使模型感到困惑并降低性能。为了获得最佳结果，位置值理应独立于序列长度。</p><h3 id="三方法3正弦位置嵌入">（三）方法3：正弦位置嵌入</h3><p>下一种方法利用正弦函数来生成位置嵌入，从而在x轴上创建一条平滑的波浪形曲线来编码单词位置。通过将单词位置映射到正弦波的高度，每个位置都会在一个有限范围内获得一个唯一值，无论序列长度如何。这种方法通过标准化位置嵌入值，缓解了之前方法中出现的扭曲风险。</p><p>然而，一个缺点出现在曲线上对称位置的单词上（例如，在可视化环境中用蓝色和紫色等颜色表示）；尽管这些单词的位置不同，但它们产生的位置值却相同，这可能导致潜在的歧义。</p><h3 id="四方法4受二进制启发的编码">（四）方法4：受二进制启发的编码</h3><p>最后，一种创新的视角借鉴了二进制表示原理。在二进制编码中，比特率的变化是可预测的；最低有效位在每个数字间交替变化，下一个较低的位在每两个数字间交替，依此类推。</p><p>将这种概念从二进制位转换为浮点数，可以实现一种紧凑且高效的编码机制，该机制能够在不占用过多计算资源的情况下保持单词位置的唯一性。这种受二进制启发的方法为Transformer中位置嵌入的设计提供了一条有前景的道路。</p><h3 id="五transformer方法使用正弦函数的位置编码">（五）Transformer方法：使用正弦函数的位置编码</h3><p>在Transformer的背景下，通过正弦函数嵌入单词位置提供了一种精细的方法来连续捕获位置信息。该解决方案通过使用交替的正弦和余弦函数，解决了传统位置编码的挑战。这些函数表示出类似于二进制位模式的连续、平滑波形，但在基于浮点数的系统中更加灵活和高效。</p><h4 id="正弦频率调制">正弦频率调制</h4><p>为了避免位置嵌入的冗余，不同位置使用不同频率的正弦函数，引入了一种微妙但强大的手段来区分序列中即使位置相近的单词。</p><p>其原理如下：如果两个点在低频正弦波上靠得很近，那么它们将难以区分；然而，高频会放大波形高度的差异。因此，每个位置及其频率共同构成了序列中单词的整体顺序信息。</p><p>这种方法依赖于根据每个嵌入维度调整正弦频率，使得在较低频率下能够区分较近的单词，而在较高频率下，相隔较远的单词则表现出明显的差异。这种频率调制确保模型能够准确识别输入中单词之间的即时和远距离关系。</p><p>因此，为了实现有效的位置编码，一个关键方面是频率调制，它必须根据嵌入向量中的每个位置而变化。在这里，变量i在产生这些变化中起着关键作用。通过在不同的i值下重新计算正弦曲线，我们在嵌入维度上生成了一系列具有不同频率的曲线，为每个位置pos创建了细微差别的位置嵌入。在这里，d=512，是位置嵌入的维度。</p><p>让我们通过一个例子来阐明这一点。假设我们需要确定位于“蓝色”和“紫色”位置的单词的位置嵌入。当在低频率下（例如，在第三个嵌入维度中）检查这些嵌入时，这两个位置的值最初可能看起来是相同的。然而，随着我们增加频率——或者向第一个嵌入维度推进——这些值开始显著不同。这种差异在高频率下尤其明显，即使是很小的位置差异也会变得非常显著。</p><p>因此，这种频率调制确保了序列中每个单词的位置嵌入保持唯一性，为模型提供了单词位置之间的强有力区分，这对于在复杂序列中保持上下文完整性至关重要。</p><h4 id="双正弦方法同时使用正弦和余弦">双正弦方法：同时使用正弦和余弦</h4><p>为了进一步增强区分度，作者 以下是关于Transformer模型生成嵌入的思路的梳理：</p><h2 id="一输入处理-1">一、输入处理</h2><p>输入处理是Transformer模型嵌入生成的第一步，目的是将文本转换为模型能够处理的数值形式。 - <strong>构建词汇表</strong>：从训练数据中提取所有不重复的单词，形成一个词汇表，并为每个单词分配一个唯一的索引。例如，对于包含“生活”、“平衡”、“自行车”等词汇的训练数据，词汇表会将这些单词映射到对应的索引。 - <strong>分词与索引映射</strong>：将输入文本分词，并将每个单词替换为词汇表中的索引。如输入文本“生活就像骑自行车”，分词后得到“生活”、“像”、“骑”、“自行车”，然后根据词汇表分别映射为对应的索引，形成一个索引序列。</p><h2 id="二词嵌入-1">二、词嵌入</h2><p>词嵌入是将索引序列转换为向量表示的过程，使模型能够捕捉单词的语义信息。 - <strong>嵌入层的作用</strong>：嵌入层是一个矩阵，其行数等于词汇表大小，列数为嵌入维度（如512维）。它将输入的索引映射为对应的嵌入向量。例如，索引1对应的行向量就是单词“生活”的嵌入向量。 - <strong>学习语义关系</strong>：在训练过程中，嵌入层的权重会不断调整，使得语义相似的单词在嵌入空间中距离更近。比如，“骑”和“自行车”因常一起出现，其嵌入向量会逐渐靠近，从而让模型理解它们之间的语义关联。</p><h2 id="三位置嵌入-1">三、位置嵌入</h2><p>由于Transformer模型本身不处理序列的顺序信息，因此需要位置嵌入来为模型提供单词顺序的感知。 - <strong>位置嵌入的必要性</strong>：单词的位置会影响其意义。例如，“苹果”在“我吃了一个苹果”和“苹果公司发布了新产品”中含义不同。位置嵌入通过为每个单词赋予与其位置相关的唯一向量，使模型能够捕捉到这种顺序信息。 - <strong>正弦位置编码</strong>：Transformer模型采用正弦和余弦函数生成位置嵌入。对于每个位置pos和维度i，位置嵌入的计算公式为： - 偶数维度：PE(pos, 2i) = sin(pos / 10000^(2i/d_model)) - 奇数维度：PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model)) 其中d_model是模型的嵌入维度。这种编码方式具有周期性，能够处理比训练时更长的序列，同时保持位置信息的一致性。</p><h2 id="四嵌入向量的整合">四、嵌入向量的整合</h2><p>将词嵌入和位置嵌入相加，得到最终的嵌入向量，作为Transformer模型的输入。 - <strong>相加操作</strong>：对于每个单词，将其词嵌入向量与对应位置的位置嵌入向量相加。例如，单词“生活”在句子中的位置为0，其词嵌入向量为E_word，位置嵌入向量为PE(0)，则最终的嵌入向量为E_word + PE(0)。 - <strong>模型输入</strong>：经过相加操作后得到的嵌入向量序列，包含了单词的语义信息和位置信息，被送入Transformer模型的后续层进行进一步处理。</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>基于ragas和evalscope实现rag快速评测</title>
    <link href="/2025/04/07/ReadingNotes/rag/rag_eval/"/>
    <url>/2025/04/07/ReadingNotes/rag/rag_eval/</url>
    
    <content type="html"><![CDATA[<hr /><h3 id="ragas-评估工具概述">Ragas 评估工具概述</h3><p>Ragas 是一个用于评估 RAG（Retrieval-Augmented Generation，检索增强生成）应用程序的工具库。它通过提供一系列工具来帮助用户轻松且自信地评估其 RAG 应用程序的性能。</p><p>Ragas 采用了一种新颖的评测数据生成方法。理想的评测数据集应该涵盖实际应用中遇到的各种类型的问题，包括不同难度等级的问题。然而，默认情况下，大语言模型（LLMs）通常不擅长创建多样化的样本，因为它们往往会遵循常见的路径。受到 Evol-Instruct 等工作的启发，Ragas 通过采用进化生成范式来实现这一目标。在这个过程中，具有不同特征的问题（如推理、条件、多个上下文等）会根据提供的文档集被系统地构建。这种方法确保了对管道中各个组件性能的全面覆盖，从而使评测过程更加稳健。</p><p>Ragas 的官网 <a href="https://docs.ragas.io/" class="uri">https://docs.ragas.io/</a> 介绍了如何通过大模型 API 接口初始化评测端模型，以实现评测指标的计算。然而，这种方式可能会受到网络连接等因素的影响，从而限制本地应用的效果。</p><h3 id="在本地部署-ragas-服务">在本地部署 Ragas 服务</h3><p>为了克服网络连接问题并提升本地应用的性能，可以通过 <a href="https://evalscope.readthedocs.io/zh-cn/latest/user_guides/backend/rageval_backend/ragas.html">EvalScope</a> 项目结合 <a href="https://vllm.hyper.ai/docs/getting-started/quickstart/">vLLM</a> 来实现本地部署。</p><h4 id="使用-vllm-构建本地-api-服务器">使用 vLLM 构建本地 API 服务器</h4><p>vLLM 是一个高性能的推理引擎，可以在本地为大语言模型构建 API 服务器。通过 vLLM，用户可以快速部署本地 Ragas 服务，从而避免网络连接问题对评估过程的影响。</p><p>以下是使用 vLLM 构建本地 API 服务器的步骤：</p><ol type="1"><li><p><strong>安装 vLLM</strong>： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install vllm<br></code></pre></td></tr></table></figure></p></li><li><p><strong>启动 vLLM 服务器</strong>： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">vllm serve facebook/opt-125m<br></code></pre></td></tr></table></figure> 默认情况下，服务器会在 <code>http://localhost:8000</code> 启动。可以通过 <code>--host</code> 和 <code>--port</code> 参数指定其他地址。</p></li><li><p><strong>使用 OpenAI API 兼容模式</strong>： vLLM 服务器支持 OpenAI API 协议，可以直接替代 OpenAI API。可以使用 <code>curl</code> 或 Python 客户端进行查询。例如： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/completions \<br>    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>    -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;model&quot;: &quot;facebook/opt-125m&quot;,</span><br><span class="hljs-string">        &quot;prompt&quot;: &quot;San Francisco is a&quot;,</span><br><span class="hljs-string">        &quot;max_tokens&quot;: 7,</span><br><span class="hljs-string">        &quot;temperature&quot;: 0</span><br><span class="hljs-string">    &#125;&#x27;</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>在 EvalScope 中使用本地 vLLM 服务</strong>： 在 EvalScope 的配置中，将评测模型的 API 基础地址设置为本地 vLLM 服务器的地址。例如： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">eval_task_cfg = &#123;<br>    <span class="hljs-string">&quot;eval_backend&quot;</span>: <span class="hljs-string">&quot;RAGEval&quot;</span>,<br>    <span class="hljs-string">&quot;eval_config&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;tool&quot;</span>: <span class="hljs-string">&quot;RAGAS&quot;</span>,<br>        <span class="hljs-string">&quot;eval&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;testset_file&quot;</span>: <span class="hljs-string">&quot;outputs/testset_with_answer.json&quot;</span>,<br>            <span class="hljs-string">&quot;critic_llm&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;model_name&quot;</span>: <span class="hljs-string">&quot;facebook/opt-125m&quot;</span>,<br>                <span class="hljs-string">&quot;api_base&quot;</span>: <span class="hljs-string">&quot;http://localhost:8000/v1&quot;</span>,<br>                <span class="hljs-string">&quot;api_key&quot;</span>: <span class="hljs-string">&quot;EMPTY&quot;</span>,<br>            &#125;,<br>            <span class="hljs-string">&quot;embeddings&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;model_name_or_path&quot;</span>: <span class="hljs-string">&quot;AI-ModelScope/m3e-base&quot;</span>,<br>            &#125;,<br>            <span class="hljs-string">&quot;metrics&quot;</span>: [<br>                <span class="hljs-string">&quot;Faithfulness&quot;</span>,<br>                <span class="hljs-string">&quot;AnswerRelevancy&quot;</span>,<br>                <span class="hljs-string">&quot;ContextPrecision&quot;</span>,<br>                <span class="hljs-string">&quot;AnswerCorrectness&quot;</span>,<br>            ],<br>            <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span><br>        &#125;,<br>    &#125;,<br>&#125;<br></code></pre></td></tr></table></figure></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>M3-Embedding Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation</title>
    <link href="/2025/03/13/ReadingNotes/rag/M3-Embedding/"/>
    <url>/2025/03/13/ReadingNotes/rag/M3-Embedding/</url>
    
    <content type="html"><![CDATA[<h2 id="研究背景">研究背景</h2><p>这篇文章要解决的问题是如何设计一种多语言、多功能、多粒度的文本嵌入模型，以支持超过100种工作语言的语义检索，并能同时完成<mark>密集检索、多向量检索和稀疏检索</mark>等多种检索功能。</p><h2 id="研究方法">研究方法</h2><h3 id="混合检索">混合检索</h3><p>M3-Embedding统一了文本嵌入模型的常见检索功能，包括密集检索、词汇（稀疏）检索和多向量检索。这些功能不仅可以单独工作，还可以协同工作以获得更强的检索质量。</p><h4 id="密集检索dense-retrieval.">密集检索（Dense retrieval.）</h4><ul><li>输入query <span class="math inline"><em>q</em></span> 将转换为基于文本编码器的隐藏状态 <span class="math inline"><strong>H</strong><sub><strong>q</strong></sub></span>。使用特殊标记 “[CLS]” 的规范化隐藏状态来表示query：<span class="math inline"><em>e</em><sub><em>q</em></sub> = norm(<strong>H</strong><sub><strong>q</strong></sub>[0])</span></li><li><p>passage的嵌入 <span class="math inline"><em>p</em></span> 为 <span class="math inline"><em>e</em><sub><em>p</em></sub> = norm(<strong>H</strong><sub><strong>p</strong></sub>[0])</span>。</p></li><li><p>因此，query和passage之间的相关性分数由两个嵌入和 <span class="math inline"><em>e</em><sub><em>q</em></sub><em>e</em><sub><em>p</em></sub></span>：<span class="math inline"><em>s</em><sub>dense</sub> ← ⟨<em>e</em><sub><em>p</em></sub>, <em>e</em><sub><em>q</em></sub>⟩</span> 之间的内积来衡量。</p></li></ul><h4 id="词汇检索lexical-retrieval.">词汇检索（Lexical Retrieval. ）</h4><ul><li>对于query中的每个token <span class="math inline"><em>t</em></span>，其权重的计算公式为</li></ul><p><br /><span class="math display"><em>w</em><sub><em>q</em><sub><em>t</em></sub></sub> ← Relu(<strong>W</strong><sub>lex</sub><sup><em>T</em></sup><strong>H</strong><sub><strong>q</strong></sub>[<em>i</em>])</span><br /></p><ul><li>其中 <span class="math inline"><strong>W</strong><sub>lex</sub> ∈ ℝ<sup><em>d</em> × 1</sup></span> 是将隐藏状态映射到浮点数的矩阵。</li><li>如果某个token <span class="math inline"><em>t</em></span> 在query中多次出现，只保留其最大权重。并使用相同的方法来计算passage中每个token的权重。</li><li>因此query和passage之间的相关性分数是通过query和passage中共存token（表示为 <span class="math inline"><em>q</em> ∩ <em>p</em></span>）的联合重要性来计算的： <br /><span class="math display"><em>s</em><sub>lex</sub> ← ∑<sub><em>t</em> ∈ <em>q</em> ∩ <em>p</em></sub>(<em>w</em><sub><em>q</em><sub><em>t</em></sub></sub> * <em>w</em><sub><em>p</em><sub><em>t</em></sub></sub>)</span><br /></li></ul><h4 id="多向量检索-multi-vector-retrieval.">多向量检索 (Multi-Vector Retrieval. )</h4><ul><li>作为密集检索的扩展，多向量检索利用整个输出嵌入来表示query和passage：</li></ul><p><br /><span class="math display"><em>E</em><sub><em>q</em></sub> = norm(<strong>W</strong><sub>mul</sub><sup><em>T</em></sup><strong>H</strong><sub><strong>q</strong></sub>)</span><br /></p><p><br /><span class="math display"><em>E</em><sub><em>p</em></sub> = norm(<strong>W</strong><sub>mul</sub><sup><em>T</em></sup><strong>H</strong><sub><strong>p</strong></sub>)</span><br /></p><ul><li><p>其中 <span class="math inline"><strong>W</strong><sub>mul</sub> ∈ ℝ<sup><em>d</em> × <em>d</em></sup></span> 是可学习的投影矩阵。</p></li><li>使用后期交互来计算细粒度的相关性分数： <br /><span class="math display">$$s_{\text{mul}} \leftarrow \frac{1}{N} \sum_{i=1}^N \max_{j=1}^M E_q[i] \cdot E_p^T[j]$$</span><br /></li><li><p><span class="math inline"><em>N</em></span> 和 <span class="math inline"><em>M</em></span> 是query和passage的长度。</p></li></ul><p>每种方法都可以单独检索候选结果（多向量方法由于成本高，可以免于此步骤）。然后，根据集成的相关性分数对最终检索结果进行重新排名：</p><p><br /><span class="math display"><em>S</em><sub>rank</sub> ← <em>w</em><sub>1</sub> ⋅ <em>S</em><sub>dense</sub> + <em>w</em><sub>2</sub> ⋅ <em>S</em><sub>lex</sub> + <em>w</em><sub>3</sub> ⋅ <em>S</em><sub>mul</sub></span><br /></p><h3 id="自我认识蒸馏self-knowledge-distillation">自我认识蒸馏(Self-Knowledge Distillation)</h3><h4 id="损失函数">损失函数</h4><p>嵌入模型经过训练以区分阳性样本和阴性样本。对于每种检索方法，与负样本相比，应为查询的正样本分配更高的分数。因此，进行训练过程以最小化 InfoNCE 损失，其一般形式由以下损失函数表示：</p><p><br /><span class="math display">$$\mathcal{L}_{s(\cdot)} = -\log \frac{\exp(s(q, p^*) / \tau)} {\sum_{p \in \{p^*, p'\}} \exp(s(q, p) / \tau)}$$</span><br /></p><p>这里，<span class="math inline"><em>p</em><sup>*</sup></span> 和 <span class="math inline"><em>p</em>′</span> 代表查询 <span class="math inline"><em>q</em></span> 的正样本和负样本</p><p><span class="math inline"><em>s</em>( ⋅ )</span> 是 <span class="math inline">{<em>s</em><sub>dense</sub>( ⋅ )</span>,<span class="math inline"><em>s</em><sub>lex</sub>( ⋅ )</span>,<span class="math inline"><em>s</em><sub>mul</sub>( ⋅ )</span> 中的任何函数。</p><ul><li>不同检索方法的训练目标可能与各自的方法相互冲突。因此，原生多目标训练可能不利于嵌入的质量。为了促进多个检索函数的优化，作者建议在自我知识蒸馏之上统一训练过程。在最简单的形式中，积分可以是不同预测分数的加权和：</li></ul><p><br /><span class="math display"><em>S</em><sub>inter</sub> ← <em>w</em><sub>1</sub> ⋅ <em>S</em><sub>dense</sub> + <em>w</em><sub>2</sub> ⋅ <em>S</em><sub>lex</sub> + <em>w</em><sub>3</sub> ⋅ <em>S</em><sub>mul</sub>.</span><br /></p><ul><li>使用积分分数 <span class="math inline"><em>S</em><sub><em>i</em><em>n</em><em>t</em><em>e</em><em>r</em></sub></span>作为老师，于是其中每种检索方法的损失函数被修改为:</li></ul><p><br /><span class="math display">ℒ<sub>*</sub><sup>′</sup> ←  − <em>p</em>(<em>s</em><sub>inter</sub>) * log <em>p</em>(<em>s</em><sub>*</sub>).</span><br /> - 这里，<span class="math inline"><em>p</em>( ⋅ )</span> 是 softmax 激活；<span class="math inline"><em>s</em><sub>*</sub></span> 是 <span class="math inline"><em>s</em><sub>dense</sub></span>、<span class="math inline"><em>s</em><sub>lex</sub></span> 和 <span class="math inline"><em>s</em><sub>mul</sub></span> 中的任何成员。我们进一步整合并归一化修改后的损失函数： <br /><span class="math display">ℒ′ ← (<em>λ</em><sub>1</sub>⋅ℒ′<sub>dense</sub>+<em>λ</em><sub>2</sub>⋅ℒ′<sub>lex</sub>+<em>λ</em><sub>3</sub>⋅ℒ′<sub>mul</sub>)/3.</span><br /></p><p>最后，用 <span class="math inline">ℒ</span> 和的 <span class="math inline">ℒ′</span> 线性组合推导出自我知识蒸馏的最终损失函数： <br /><span class="math display">ℒ<sub>final</sub> ← (ℒ+ℒ′)/2</span><br /></p><h4 id="训练过程">训练过程</h4><p>训练过程包括一个<strong>多阶段工作流</strong>（如图所示）。首先，文本编码器（XLM-RoBERTa模型）使用大量无监督数据进行预训练，其中仅以基本形式的对比学习训练密集检索。</p><p>在第二阶段应用自知识蒸馏，其中嵌入模型被微调以建立三个检索功能。<span class="math inline"><strong>W</strong><sub>lex</sub></span>的随机初始化导致<span class="math inline"><em>s</em><sub>lex</sub></span>准确性差和训练开始时的<span class="math inline">ℒ<sub>lex</sub></span>高。</p><p><img src="/images/m3-embedding训练过程.png" /></p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/02/25/hello-world/"/>
    <url>/2025/02/25/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo搭建博客实现多端同步</title>
    <link href="/2025/02/25/essays/Hexo/hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/"/>
    <url>/2025/02/25/essays/Hexo/hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="基于hexogithub实现博客撰写的多端同步功能">基于hexo+github实现博客撰写的多端同步功能</h1><p>hexo 本身自带的同步功能<code>hexo d</code>上传的只是网页部署文件，未上传网页源文件，所以如果我们要在另一台设备上对博客进行修改的话就会遇到困难。我们可以在在github的blog仓库新建一个分支，存储源文件，然后在不同设备间同步源文件。这样就可以实现博客在不同设备上的同步了。</p><h2 id="github对应的仓库新建分支">github对应的仓库新建分支</h2><p>首先你需要在你博客对应的github仓库(比如我的就是<code>https://github.com/yangyihui2020/yangyihui2020.github.io)</code>新建分支<code>hexo</code>。</p><h2 id="在已有博客文件的旧设备上执行的操作">在已有博客文件的旧设备上执行的操作 ：</h2><p>然后在本地任意目录下执行 <code>git clone</code>。并切换到对应分支： <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git clone git@github<span class="hljs-selector-class">.com</span>:yangyihui2020/yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.git</span><br>cd yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><br>git <span class="hljs-selector-tag">switch</span> hexo<br></code></pre></td></tr></table></figure></p><p>然后删除掉仓库目录（比如我的就是<code>yangyihui2020.github.io</code>)下除去.git之外的所有文件，并将原博客目录下的所有文件复制到该目录下。</p><p>然后上传到hexo分支</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">git</span> <span class="hljs-keyword">add</span> .<br><span class="hljs-symbol">git</span> commit -m <span class="hljs-string">&quot;新建hexo分支&quot;</span><br><span class="hljs-symbol">git</span> <span class="hljs-keyword">push</span> <br></code></pre></td></tr></table></figure><h2 id="在新设备上执行的操作">在新设备上执行的操作 ：</h2><p>在新设备，你需要提前配置好hexo所需要的环境。可以参考<a href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a> 。</p><p>然后在任意目录下新建一个目录<code>blogs</code>(这个名字随意),进入该目录执行<code>hexo init</code>。 然后清空该目录的文件，并执行<code>git clone</code>并切换到对应的分支: <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git clone git@github<span class="hljs-selector-class">.com</span>:yangyihui2020/yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.git</span><br>git <span class="hljs-selector-tag">switch</span> hexo<br></code></pre></td></tr></table></figure></p><p>然后你就可以在不同设备上实现hexo博客的源文件共享了。 <div class="note note-info">            <p>注意，每次写博客之前最好执行<code>git pull</code>，上传网页后同时执行一下<code>git push</code>来保持文件的同步</p>          </div></p><h2 id="可能会遇到的问题">可能会遇到的问题</h2><div class="note note-danger">            <p>在这个过程中可能会遇到<code>hexo g</code>等命令不起作用的情况，hexo提示的命令也变少了.</p>          </div><div class="note note-info">            <p>这个时候你就要观察你执行命令的目录是否是你博客真正对应的目录。 比如我执行完上述操作后，我的博客目录应该是yangyihui2020.github.io，而不是blogs。 你必须要在博客对应目录下执行对应操作才行。</p>          </div>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</title>
    <link href="/2025/02/24/ReadingNotes/rag/Retrieval-Augmented%20Generation%20for%20%20Knowledge-Intensive%20NLP%20Tasks/"/>
    <url>/2025/02/24/ReadingNotes/rag/Retrieval-Augmented%20Generation%20for%20%20Knowledge-Intensive%20NLP%20Tasks/</url>
    
    <content type="html"><![CDATA[<h1 id="rag-检索增强生成技术背景介绍">RAG 检索增强生成技术背景介绍</h1><p>RAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合了信息检索技术与语言生成模型的人工智能技术。该技术通过从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型（LLMs），以增强模型处理知识密集型任务的能力，如问答、文本摘要、内容生成等。RAG模型由Facebook AI Research（FAIR）团队于2020年首次提出，并迅速成为大模型应用中的热门方案。(这篇论文可以说是RAG技术的开山之作)</p><p><img src="/images/rag.jpg" /></p><p>RAG一般有3个步骤： 1. 检索：检索是RAG流程的第一步，从预先建立的知识库中检索与问题相关的信息。这一步的目的是为后续的生成过程提供有用的上下文信息和知识支撑。</p><ol start="2" type="1"><li><p>增强：RAG中增强是将检索到的信息用作生成模型（即大语言模型）的上下文输入，以增强模型对特定问题的理解和回答能力。这一步的目的是将外部知识融入生成过程中，使生成的文本内容更加丰富、准确和符合用户需求。通过增强步骤，LLM模型能够充分利用外部知识库中的信息。</p></li><li><p>生成：生成是RAG流程的最后一步。这一步的目的是结合LLM生成符合用户需求的回答。生成器会利用检索到的信息作为上下文输入，并结合大语言模型来生成文本内容。</p></li></ol><h1 id="rag-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks">RAG Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</h1><p><a href="https://arxiv.org/abs/2005.11401">文章链接</a></p><h2 id="研究背景">研究背景</h2><p>这篇文章的研究背景是大型预训练语言模型虽然能够在下游NLP任务中存储事实性知识并取得优异表现，但在访问和精确操作知识方面仍然有限。因此，在知识密集型任务中，这些模型的表现落后于特定任务的架构。此外，提供决策的可追溯性和更新世界知识仍然是开放的研究问题。</p><p>文章着眼于此，提出的RAG模型通过结合预训练的参数化记忆和非参数化记忆，在知识密集型NLP任务中取得了显著的性能提升。 ## 研究方法</p><p>这篇论文提出了两种RAG模型：RAG-Sequence和RAG-Token，用于解决知识密集型任务中的生成问题：</p><ol type="1"><li>​<strong>RAG-Sequence模型:</strong>​ 该模型使用相同的检索文档来生成整个序列。它将检索到的文档视为一个单一的潜在变量，并通过top-K近似来边缘化以获得seq2seq概率。 <img src="/images/RAG-Sequence-Model.png" alt="RAG-Sequence-Model相应公式" /></li><li>​<strong>RAG-Token模型:</strong>​ 该模型为每个目标标记抽取不同的潜在文档，并相应地进行边缘化。这允许生成器在生成答案时从多个文档中选择内容。具体来说，使用检索器检索前 K 个文档，然后生成器为每个文档的下一个输出标记生成一个分布，然后边缘化，并使用以下输出标记重复该过程。 <img src="/images/RAG-Token-Model.png" alt="alt text" /></li></ol><p>检索器：使用DPR（Dense Passage Retriever）作为检索组件，采用双向编码器架构，通过最大内积搜索（MIPS）问题近似求解top-K文档。 <img src="/images/Retriever.png" alt="alt text" /> 生成器：使用BART-large作为生成器组件，通过连接输入和检索内容来生成输出。</p><h2 id="实验">实验</h2><p>实验采用了多个知识密集型NLP任务的数据集，包括自然问题（NQ）、TriviaQA（TQA）、WebQuestions（WQ）、CuratedTrec（CT）、MS-MARCO、Jeopardy问题生成和FEVER。</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>THE power of noise</title>
    <link href="/2025/02/24/ReadingNotes/rag/The%20Power%20of%20Noise-Redefining%20Retrieval%20for%20RAG%20Systems/"/>
    <url>/2025/02/24/ReadingNotes/rag/The%20Power%20of%20Noise-Redefining%20Retrieval%20for%20RAG%20Systems/</url>
    
    <content type="html"><![CDATA[<p>ddgf</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>用hexo+fluid配置个人博客</title>
    <link href="/2025/02/22/essays/Hexo/%E7%94%A8hexo+fluid%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2025/02/22/essays/Hexo/%E7%94%A8hexo+fluid%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="环境准备">环境准备</h1><p>在开始之前，你需要先参考<a href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a>进行安装、建站。</p><h2 id="然后设置你的主题为fluid">然后设置你的主题为fluid：</h2><ul><li><p>进入博客目录执行命令：<code>npm install --save hexo-theme-fluid</code></p></li><li><p>修改 Hexo 博客目录下<code>_config.yml</code>中的对应参数：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span>  <span class="hljs-comment"># 指定主题为fluid</span><br></code></pre></td></tr></table></figure><h1 id="开始新文档创建">开始新文档创建</h1><h2 id="创建关于页">创建<code>关于页</code></h2><ul><li><p>在博客目录下执行命令：<code>hexo new page about</code></p></li><li><p>创建成功后修改 <code>/source/about/index.md</code>，在其中添加 <code>layout</code> 属性。</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">标题</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">about</span><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-string">这里写关于页的正文，支持</span> <span class="hljs-string">Markdown,</span> <span class="hljs-string">HTML</span><br></code></pre></td></tr></table></figure><div class="note note-info">            <p>根据官方文档，<code>layout: about</code> 必须存在，并且不能修改成其他值，否则不会显示头像等样式。</p><p>一般<code>关于页</code>可以介绍你的个人资料</p>          </div><h2 id="创建新的文章并为其归类这里的做法为个人偏好仅供参考">创建新的文章并为其归类。（这里的做法为个人偏好，仅供参考）</h2><p>我现在需要写一篇名为<code>用hexo+fluid配置个人博客</code>的文章，我想给其分类到<code>随笔</code>下的<code>Hexo</code>小类中，这里我就用到了hexo的二级导航功能。具体做法如下：</p><h3 id="生成分类页并添加tpye属性">生成“分类”页并添加tpye属性</h3><ul><li><p>进入博客所在文件夹。执行命令：<code>hexo new page categories</code></p></li><li><p>修改博客目录下的<code>source/categories/index.md</code>为：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">categories</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-22 19:55:44</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">categories</span> <span class="hljs-comment">#添加这一行代码到原md文件中</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><h3 id="创建随笔hexo类别">创建<code>随笔\Hexo</code>类别：</h3><ul><li><p>在 <code>source/categories</code> 文件夹下创建一个名为 <code>essay</code> 的文件夹,再在<code>essay</code>文件夹内新建<code>Hexo</code>文件夹</p></li><li><p>在<code>source/categories/essay/和</code> <code>source/categories/essay/Hexo</code> 文件夹下均创建一个名为 <code>index.md</code> 的文件，内容如下</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-22 19:57:44</span><br><span class="hljs-attr">type:</span> <span class="hljs-string">categories</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><ul><li>修改主题目录下的<code>_config.yaml</code>文件中的menu属性，它将影响到网页中的菜单栏，修改为：</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">menu:</span><br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;home&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont icon-home-fill&quot;</span> &#125;<br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;随笔&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/categories/essay/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont book icon-book&quot;</span>,<br>    <span class="hljs-attr">submenu:</span> [&#123;<span class="hljs-attr">key:</span> <span class="hljs-string">&#x27;Hexo用户笔记&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;/categories/essay/Hexo/&#x27;</span>&#125;,],&#125;<br>  <span class="hljs-comment"># 设置你的多级目录以及设置key的值作为菜单栏中展示的分类名</span><br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;about&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/about/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont icon-user-fill&quot;</span>,&#125;<br>  <span class="hljs-comment">#- &#123; key: &quot;archive&quot;, link: &quot;/archives/&quot;, icon: &quot;iconfont icon-archive-fill&quot; &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;categories&quot;, link: &quot;/categories/&quot;, icon: &quot;iconfont icon-category-fill&quot;, &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;tag&quot;, link: &quot;/tags/&quot;, icon: &quot;iconfont icon-tags-fill&quot; &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;links&quot;, link: &quot;/links/&quot;, icon: &quot;iconfont icon-link-fill&quot; &#125;</span><br></code></pre></td></tr></table></figure><div class="note note-info">            <p>注意，我这里注释掉了不必要的菜单栏</p>          </div><h3 id="创建新的文章并归类">创建新的文章并归类:</h3><ul><li><p>在<code>source\_posts</code>目录下新建<code>essays\Hexo</code>目录结构</p></li><li><p>执行<code>hexo new 用hexo+fluid配置个人博客 -p essays\Hexo\用hexo+fluid配置个人博客</code></p></li><li><p>修改<code>source\_posts\essays\Hexo\用hexo+fluid配置个人博客.md</code>中的内容为：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">用hexo+fluid配置个人博客</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-23 14:36:55</span><br><span class="hljs-attr">tags:</span><br><span class="hljs-attr">categories:</span> [<span class="hljs-string">essay</span>,<span class="hljs-string">Hexo</span>] <span class="hljs-comment">#加上这一栏即可</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p>执行完上述一系列操作之后，你将得到这样一个界面：</p><p><img src="/images/image-20250223144908444.jpg" /></p><p>然后你就可以编辑<code>用hexo+fluid配置个人博客.md</code>中的内容作为你的第一篇博客了。</p>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
