<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title></title>
    <link href="/2025/04/13/essays/%E9%9A%8F%E7%AC%94/mysql+vscode%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%20(copy)/"/>
    <url>/2025/04/13/essays/%E9%9A%8F%E7%AC%94/mysql+vscode%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%20(copy)/</url>
    
    <content type="html"><![CDATA[<h1 id="mysqlvscode环境配置">mysql+vscode环境配置</h1><h2 id="一mysql安装">一、mysql安装</h2><p><font color=red size=4>系统环境为win11</font></p><ol type="1"><li><p><strong>下载</strong><a href="https://downloads.mysql.com/archives/installer/">mysql80</a></p><img src="mysql+vscode环境配置/2025-04-13-18-51-30.png" /><ul><li>下载完成后直接双击安装</li></ul></li><li><strong>Choosing a Setup Type</strong><ul><li>选择Custom安装（如果你内存充足，可以直接选Full) <img src="mysql+vscode环境配置/2025-04-13-19-00-48.png" /></li></ul></li><li><p><strong>选择想要安装的产品</strong>（注意server和workbench是必须的） <img src="mysql+vscode环境配置/2025-04-13-19-00-28.png" /></p></li></ol><p><font color=red size=4>注意这里有一个很小的选项<code>Advanced Options</code>,可以更改你的安装路径</font></p><ol start="4" type="1"><li><p>选完之后直接点<strong>执行</strong>就可开始安装了 <img src="mysql+vscode环境配置/2025-04-13-19-04-32.png" /></p></li><li>安装完成之后就是一路 <code>next</code>,然后开始<strong>设置你的root密码</strong> <img src="mysql+vscode环境配置/2025-04-13-19-07-16.png" /></li><li><p>设置完之后还是一路<code>next</code>,<strong>点击<code>finish</code></strong>就可以完成你的mysql安装了</p></li></ol><p><font color=red size=4>有同学会在检查依赖卡住，只需要通过安装界面提示安装所需库。 比如显示缺少库<a href="https://aka.ms/vs/17/release/vc_redist.x86.exe"><strong>VC_redist_x64</strong></a>，下载安装即可。</font></p><h2 id="二配置环境变量与验证mysql可用性">二、配置环境变量与验证mysql可用性</h2><p>到目前为止大家打开命令行, 直接输入<code>mysql</code>命令会报错，因为还没有设置相关的环境变量。 <img src="mysql+vscode环境配置/2025-04-13-19-11-31.png" /> 按照下面的步骤可以实现mysql环境变量的设置与在命令行中</p><ol type="1"><li><strong>确认mysql的安装地址</strong><ul><li>比如我的就是<code>D:\MySQL</code>，该地址下会安装有mysql的exe可执行文件</li></ul><p><img src="mysql+vscode环境配置/2025-04-13-19-14-14.png" /></p></li><li><p>复制该地址，然后将其<strong>添加到系统变量的PATH中</strong> <img src="mysql+vscode环境配置/2025-04-13-19-18-06.png" /></p></li><li><p>这时重新打开终端输入mysql就可用了</p></li></ol><p><font color=red size=4>如果还是不行，可以重启电脑再试试</font></p><ol start="4" type="1"><li>从命令行连接mysql<ul><li><p>使用<code>mysql -u &lt;usr_name&gt; -p</code>登录</p></li><li>因为这里这里我还没有新建用户，所以登录用户就是root，登录密码就是刚刚安装mysql所用的密码，登录如下： <img src="mysql+vscode环境配置/2025-04-13-19-21-49.png" /></li></ul></li><li>关于在命令行中使用mysql的操作这里就不赘述了<ul><li>感兴趣的同学可以参考 <a href="https://www.oryoy.com/news/ru-he-shi-yong-cmd-ming-ling-xing-jin-ru-mysql-shu-ju-ku-xiang-xi-bu-zhou-jie-xi.html">如何使用CMD命令行进入MySQL数据库：详细步骤解析</a></li></ul></li></ol><h2 id="三在vscode中使用mysql">三、在vscode中使用mysql</h2><p>mysql可以直接在命令行中使用，也可以在workbench中使用，这里就不一一介绍相关用法了，感兴趣的同学可以自行百度，这里主要介绍在vscode中使用mysql</p><ol type="1"><li><strong>安装插件</strong><ul><li>在vscode中安装以下两个插件 <img src="mysql+vscode环境配置/2025-04-13-19-29-20.png" /></li><li>安装完左边会出现database的选项，点击即可进行连接 <img src="mysql+vscode环境配置/2025-04-13-19-30-45.png" /></li></ul></li><li><strong>连接mysql</strong><ul><li>服务类型选<code>Mysql</code>,然后按照你的偏好设置相关配置（如果不出意外的话，这里你只需要填写你的root密码，其他的使用默认的即可） <img src="mysql+vscode环境配置/2025-04-13-19-33-07.png" /></li><li>连接成功后vsocode的左侧会如图所示 <img src="mysql+vscode环境配置/2025-04-13-19-34-42.png" /></li></ul></li><li><strong>创建一个数据库</strong><ul><li>比如我这里创建一个数据库名为<code>lab1</code>，点击对应的按钮，修改数据库名 <img src="mysql+vscode环境配置/2025-04-13-19-36-24.png" /></li><li>然后点击<code>run</code>，就可以成功创建一个名为<code>lab1</code>的数据库 <img src="mysql+vscode环境配置/2025-04-13-19-36-58.png" /></li><li>然后即可在该数据库中执行建表查询等操作了</li></ul></li><li><p>在vscode中直接<strong>创建表</strong> <img src="mysql+vscode环境配置/2025-04-13-19-41-25.png" /></p></li><li><p>在vscode中直接进行<strong>查询</strong> <img src="mysql+vscode环境配置/2025-04-13-19-43-07.png" /></p></li></ol><p><font color=red size=4>其他操作感兴趣的同学可以自行尝试，如创建视图等操作，这里就不一一赘述了</font></p><h2 id="写在最后">写在最后</h2><p>有需要的同学可以参考其他相关教程</p><ul><li><a href="https://juejin.cn/post/6844903831298375693">MAC安装mysql教程</a>、</li><li><a href="https://blog.csdn.net/weixx3/article/details/80782479">ubuntu安装mysql教程</a></li><li><a href="https://runoob.com/mysql/mysql-install.html">mysql安装</a></li><li><a href="https://www.jianshu.com/p/118e1c41e9f0">sql命令参考</a></li></ul>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>mysql+vscode环境配置</title>
    <link href="/2025/04/13/essays/%E9%9A%8F%E7%AC%94/mysql+vscode%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    <url>/2025/04/13/essays/%E9%9A%8F%E7%AC%94/mysql+vscode%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="mysqlvscode环境配置">mysql+vscode环境配置</h1><h2 id="一mysql安装">一、mysql安装</h2><div class="note note-info">            <p>文章的系统环境为win11</p>          </div><ol type="1"><li><p><strong>下载</strong><a href="https://downloads.mysql.com/archives/installer/">mysql80</a></p><img src="2025-04-13-18-51-30.png" /><ul><li>下载完成后直接双击安装</li></ul></li><li><strong>Choosing a Setup Type</strong><ul><li>选择Custom安装（如果你内存充足，可以直接选Full) <img src="2025-04-13-19-00-48.png" /></li></ul></li><li><p><strong>选择想要安装的产品</strong>（注意server和workbench是必须的） <img src="2025-04-13-19-00-28.png" /></p></li></ol><div class="note note-info">            <p>注意这里有一个很小的选项<code>Advanced Options</code>,可以更改你的安装路径</p>          </div><ol start="4" type="1"><li><p>选完之后直接点<strong>执行</strong>就可开始安装了 <img src="2025-04-13-19-04-32.png" /></p></li><li>安装完成之后就是一路 <code>next</code>,然后开始<strong>设置你的root密码</strong> <img src="2025-04-13-19-07-16.png" /></li><li><p>设置完之后还是一路<code>next</code>,<strong>点击<code>finish</code></strong>就可以完成你的mysql安装了</p></li></ol><div class="note note-info">            <p>有同学会在检查依赖卡住，只需要通过安装界面提示安装所需库。 比如显示缺少库<a href="https://aka.ms/vs/17/release/vc_redist.x86.exe"><strong>VC_redist_x64</strong></a>，下载安装即可。</p>          </div><h2 id="二配置环境变量与验证mysql可用性">二、配置环境变量与验证mysql可用性</h2><p>到目前为止大家打开命令行, 直接输入<code>mysql</code>命令会报错，因为还没有设置相关的环境变量。 <img src="2025-04-13-19-11-31.png" /> 按照下面的步骤可以实现mysql环境变量的设置与在命令行中</p><ol type="1"><li><strong>确认mysql的安装地址</strong><ul><li>比如我的就是<code>D:\MySQL</code>，该地址下会安装有mysql的exe可执行文件</li></ul><p><img src="2025-04-13-19-14-14.png" /></p></li><li><p>复制该地址，然后将其<strong>添加到系统变量的PATH中</strong> <img src="2025-04-13-19-18-06.png" /></p></li><li><p>这时重新打开终端输入mysql就可用了</p></li></ol><div class="note note-info">            <p>如果还是不行，可以重启电脑再试试</p>          </div><ol start="4" type="1"><li>从命令行连接mysql<ul><li><p>使用<code>mysql -u &lt;usr_name&gt; -p</code>登录</p></li><li>因为这里这里我还没有新建用户，所以登录用户就是root，登录密码就是刚刚安装mysql所用的密码，登录如下： <img src="2025-04-13-19-21-49.png" /></li></ul></li><li>关于在命令行中使用mysql的操作这里就不赘述了<ul><li>感兴趣的同学可以参考 <a href="https://www.oryoy.com/news/ru-he-shi-yong-cmd-ming-ling-xing-jin-ru-mysql-shu-ju-ku-xiang-xi-bu-zhou-jie-xi.html">如何使用CMD命令行进入MySQL数据库：详细步骤解析</a></li></ul></li></ol><h2 id="三在vscode中使用mysql">三、在vscode中使用mysql</h2><div class="note note-info">            <p>mysql可以直接在命令行中使用，也可以在workbench中使用，这里就不一一介绍相关用法了，感兴趣的同学可以自行百度，这里主要介绍在vscode中使用mysql</p>          </div><ol type="1"><li><strong>安装插件</strong><ul><li>在vscode中安装以下两个插件 <img src="2025-04-13-19-29-20.png" /></li><li>安装完左边会出现database的选项，点击即可进行连接 <img src="2025-04-13-19-30-45.png" /></li></ul></li><li><strong>连接mysql</strong><ul><li>服务类型选<code>Mysql</code>,然后按照你的偏好设置相关配置（如果不出意外的话，这里你只需要填写你的root密码，其他的使用默认的即可） <img src="2025-04-13-19-33-07.png" /></li><li>连接成功后vsocode的左侧会如图所示 <img src="2025-04-13-19-34-42.png" /></li></ul></li><li><strong>创建一个数据库</strong><ul><li>比如我这里创建一个数据库名为<code>lab1</code>，点击对应的按钮，修改数据库名 <img src="2025-04-13-19-36-24.png" /></li><li>然后点击<code>run</code>，就可以成功创建一个名为<code>lab1</code>的数据库 <img src="2025-04-13-19-36-58.png" /></li><li>然后即可在该数据库中执行建表查询等操作了</li></ul></li><li><p>在vscode中直接<strong>创建表</strong> <img src="2025-04-13-19-41-25.png" /></p></li><li><p>在vscode中直接进行<strong>查询</strong> <img src="2025-04-13-19-43-07.png" /></p></li></ol><div class="note note-info">            <p>其他操作感兴趣的同学可以自行尝试，如创建视图等操作，这里就不一一赘述了</p>          </div><h2 id="写在最后">写在最后</h2><p>有需要的同学可以参考其他相关教程</p><ul><li><a href="https://juejin.cn/post/6844903831298375693">MAC安装mysql教程</a>、</li><li><a href="https://blog.csdn.net/weixx3/article/details/80782479">ubuntu安装mysql教程</a></li><li><a href="https://runoob.com/mysql/mysql-install.html">mysql安装</a></li><li><a href="https://www.jianshu.com/p/118e1c41e9f0">sql命令参考</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>随笔</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>CogLTX Applying BERT to Long Texts</title>
    <link href="/2025/04/13/ReadingNotes/rag/CogLTX/"/>
    <url>/2025/04/13/ReadingNotes/rag/CogLTX/</url>
    
    <content type="html"><![CDATA[<p>这是一篇来自Nips20的文章，提出了CogLTX框架，旨在解决BERT模型处理长文本时的内存和时间消耗问题。</p><h2 id="研究背景">研究背景</h2><p>BERT模型在处理长文本时面临内存和时间消耗呈二次增长的局限性。</p><ul><li>长文本的直接预训练的最大位置嵌入通常在BERT模型中限制为512个标记。</li><li>然而，即使提供了更大位置的嵌入，由于在训练期间需要存储所有激活以进行反向传播，内存消耗仍然可能无法承受。例如，一个包含500个标记的文本即使批量大小为1，也需要大约14.6GB的内存来运行BERT-large模型，这超出了常见GPU的容量（例如RTX 2080ti为11GB）。</li><li>此外，计算复杂度<span class="math inline"><em>O</em>(<em>L</em><sup>2</sup>)</span>随着文本长度L的增加而迅速增长，这进一步加剧了长文本处理的挑战。</li></ul><p>现有的解决方案如滑动窗口或简化变换器存在长距离注意力不足或需要定制CUDA内核的问题。</p><h2 id="方法">方法</h2><p>这篇论文提出了一种名为 <strong>CogLTX</strong> 的框架，旨在将 BERT 应用于长文本处理。其方法论基于人类认知理论，通过模拟人类工作记忆（Working Memory）的机制来处理长文本。</p><h3 id="cogltx-的核心假设">CogLTX 的核心假设</h3><p>CogLTX 的核心假设是： - <strong>关键句子假设</strong>：对于大多数 NLP 任务，长文本中只有少数关键句子包含完成任务所需的信息。这些关键句子可以被提取并组合成一个较短的文本 <span class="math inline"><em>z</em></span>，满足： <br /><span class="math display">$$  \text{reasoner}(x^+) \approx \text{reasoner}(z^+)\\  $$</span><br /> 其中 <span class="math inline"><em>x</em><sup>+</sup></span> 和 <span class="math inline"><em>z</em><sup>+</sup></span> 分别长文本 <span class="math inline"><em>x</em></span> 和关键文本 <span class="math inline"><em>z</em></span> 针对 BERT 的输入。</p><h3 id="cogltx-的关键组件"><strong>CogLTX 的关键组件</strong></h3><p>CogLTX 包含两个主要组件：<strong>MemRecall</strong> 和 <strong>Judge</strong>。</p><h4 id="memrecall"><strong>MemRecall</strong></h4><p>MemRecall 是一个模拟人类工作记忆的过程，负责从长文本 <span class="math inline"><em>x</em></span> 中提取关键文本块 <span class="math inline"><em>z</em></span>。其工作流程如下：</p><ol type="1"><li><strong>输入</strong>：长文本 <span class="math inline"><em>x</em></span> 和初始关键文本 <span class="math inline"><em>z</em><sup>+</sup></span>。</li><li><strong>检索竞争（Retrieval Competition）</strong>：<ul><li>对每个文本块 <span class="math inline"><em>x</em><sub><em>i</em></sub></span>，计算其与当前 <span class="math inline"><em>z</em><sup>+</sup></span> 的相关性分数： <br /><span class="math display">$$\text{score}[x_i] = \text{judge}([z^+ \text{SEP} x_i])[x_i]\\$$</span><br /></li><li>选择分数最高的若干块加入 <span class="math inline"><em>z</em></span>，直到 <span class="math inline"><em>z</em><sup>+</sup></span> 的长度超过 BERT 的最大长度限制 $ L $。</li></ul></li><li><strong>复习与衰减（Rehearsal &amp; Decay）</strong>：<ul><li>对已加入 $ z $ 的每个块 $ z_i $，重新计算其在 $ z^+ $ 中的细粒度相关性分数： <br /><span class="math display">$$\text{score}[z_i] = \text{judge}(z^+)[z_i]\\$$</span><br /></li><li>保留分数最高的若干块，其余块从 $ z $ 中移除。</li></ul></li><li><strong>多步推理（Multi-step Reasoning）</strong>：<ul><li>通过重复上述过程，逐步扩展 $ z $，直到满足任务需求。</li></ul></li></ol><h4 id="judge"><strong>Judge</strong></h4><p>Judge 是一个 BERT 模型，用于评估$ z^+ $中每个文本块的相关性。 <br /><span class="math display">$$\text{judge}(\mathbf{z}^+) = \text{sigmoid}(\text{MLP}(\text{BERT}(\mathbf{z}^+))) \in (0, 1)^{\text{len}(\mathbf{z}^+)}\\\$$</span><br /> 其中，<img src="2025-04-14-15-29-13.png" /> MLP 是一个简单的多层感知机，用于将 BERT 的输出映射到相关性分数。</p><h2 id="训练方法"><strong>训练方法</strong></h2><p>CogLTX 的训练分为两种情况：有监督训练和无监督训练。</p><h3 id="有监督训练"><strong>有监督训练</strong></h3><p>对于有标注的任务（如问答任务），可以直接使用标注信息训练 Judge 和 Reasoner： - <strong>Judge 的损失函数</strong>： <br /><span class="math display">$$  \text{loss}_{\text{judge}}(z) = \text{CrossEntropy}(\text{judge}(z^+), \text{relv\_label}(z^+))\\  $$</span><br /> 其中，<span class="math inline">relv_label(<em>z</em><sup>+</sup>)</span> 是标注的相关性标签。 - <strong>Reasoner 的损失函数</strong>： <br /><span class="math display">$$  \text{loss}_{\text{reasoner}} = \text{CrossEntropy}(\text{reasoner}(z^+), y)\\  $$</span><br /></p><h3 id="无监督训练"><strong>无监督训练</strong></h3><p>对于没有标注的任务，CogLTX 通过干预（Intervention）来推断相关性标签： - <strong>干预方法</strong>： - 对于每个块 $ z_i $，计算移除该块后的损失变化：</p><p><br /><span class="math display">$$\Delta \text{loss}=f(z^+ - z_i)- f((z^+));   \\ f=\text{loss}_{\text{reasoner}}$$</span><br /></p><ul><li>如果 <span class="math inline"><em>Δ</em>loss &gt; <em>t</em><sub>up</sub></span>，则标记 $ z_i $ 为相关；如果 <span class="math inline"><em>Δ</em>loss &lt; <em>t</em><sub>down</sub></span>，则标记为不相关。</li></ul><h2 id="实验验证"><strong>实验验证</strong></h2><p>CogLTX 在多个长文本任务上进行了实验验证，包括： - <strong>阅读理解（NewsQA）</strong>：CogLTX 在 EM 和 F1 指标上均优于滑动窗口方法和其他基线模型。 - <strong>多跳问答（HotpotQA）</strong>：CogLTX 在多跳问答任务上表现优异，接近 SOTA 模型。 - <strong>文本分类（20NewsGroups）</strong>：CogLTX 在文本分类任务上优于其他基于 BERT 的方法。 - <strong>多标签分类（Alibaba 数据集）</strong>：CogLTX 在多标签分类任务上表现出色，优于常见基线模型。</p><h2 id="总结"><strong>总结</strong></h2><p>CogLTX 通过模拟人类工作记忆的机制，有效地解决了 BERT 在长文本处理中的内存和时间瓶颈问题。其关键在于通过 MemRecall 提取关键文本块，并通过 Judge 模型评估相关性。实验结果表明，CogLTX 在多个长文本任务上均取得了优异的性能，且内存消耗与文本长度无关。</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2025/04/13/hello-world/"/>
    <url>/2025/04/13/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo+vscode实现快速图片插入</title>
    <link href="/2025/04/11/essays/Hexo/hexo%E5%BF%AB%E9%80%9F%E5%9B%BE%E7%89%87%E6%8F%92%E5%85%A5/"/>
    <url>/2025/04/11/essays/Hexo/hexo%E5%BF%AB%E9%80%9F%E5%9B%BE%E7%89%87%E6%8F%92%E5%85%A5/</url>
    
    <content type="html"><![CDATA[<p>我们通常使用hexo框架插入图片时，图片通常会被保存到一个绝对路径的文件夹下<code>\source\images</code>, 这样比较麻烦，这里介绍一种可以直接在插入保存到粘贴板中的方法。</p><h4 id="首先使用hexo-new命令来创建文章比如我使用">首先使用<code>hexo new</code>命令来创建文章，比如我使用</h4><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">hexo <span class="hljs-keyword">new</span> post hexo+vscode实现快速图片插入 -p essays<span class="hljs-regexp">/Hexo/</span>hexo快速图片插入<br></code></pre></td></tr></table></figure><p>该命令会新建一个md文件和与md文件同名的文件夹，我们就可以使用该文件夹来储存图片。</p><h4 id="然后在vscode的扩展中新增paste-image插件同时在vscode-的settings.json新加配置">然后在vscode的扩展中新增paste image插件，同时在vscode 的settings.json新加配置:</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-string">&quot;pasteImage.path&quot;</span>: <span class="hljs-string">&quot;<span class="hljs-variable">$&#123;currentFileDir&#125;</span>/<span class="hljs-variable">$&#123;currentFileNameWithoutExt&#125;</span>&quot;</span> <br><br></code></pre></td></tr></table></figure><h4 id="然后使用快捷键ctrl-alt-v就可以快速保存图片并且插入图片url">然后使用快捷键ctrl-alt-v就可以快速保存图片并且插入图片url。</h4><p><img src="2025-04-11-17-18-08.png" /></p><div class="note note-info">            <p>如果图片无法正常加载，可使用hexo clean清除缓存</p>          </div>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo新建文章到指定目录的方式</title>
    <link href="/2025/04/11/essays/Hexo/hexo%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95/"/>
    <url>/2025/04/11/essays/Hexo/hexo%E6%96%B0%E5%BB%BA%E6%96%87%E7%AB%A0%E5%88%B0%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95/</url>
    
    <content type="html"><![CDATA[<p>使用 -p参数指定文章生成的路径</p><figure class="highlight gradle"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs gradle">hexo <span class="hljs-keyword">new</span> post hexo新建文章到指定目录的方式 -p essays<span class="hljs-regexp">/Hexo/</span>hexo新建文章到指定目录<br></code></pre></td></tr></table></figure><p>上述命令，会在<code>\source\_posts\essays\Hexo</code>目录下新建一个<code>hexo新建文章到指定目录.md</code>文件，对应的文章标题为hexo新建文章到指定目录的方式</p>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>大模型编码梳理</title>
    <link href="/2025/04/11/ReadingNotes/rag/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BC%96%E7%A0%81%E6%A2%B3%E7%90%86/"/>
    <url>/2025/04/11/ReadingNotes/rag/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%BC%96%E7%A0%81%E6%A2%B3%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h2 id="大模型编码梳理">大模型编码梳理</h2><p>本部分将以Transformer模型为例，梳理大模型生成嵌入的思路。</p><p>（参考<a href="https://www.atyun.com/60798.html">解码Transformer：深入理解输入、嵌入和位置编码</a>）</p><p>计算机无法直接理解人类语言。它们需要将文本以数字形式表示——使用向量、矩阵或数字序列。这种转换使得像Transformer这样的模型能够处理数据并从中学习。以Transformer为代表的模型通常生成嵌入的思路如下：</p><h3 id="一将输入文本转换成序列">一、将输入文本转换成序列</h3><p>使用任何机器学习模型的第一步都是处理输入数据。假如我们现在有这样一个输入文本是： <figure class="highlight axapta"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs axapta">“Life <span class="hljs-keyword">is</span> <span class="hljs-keyword">like</span> riding a bicycle”<br></code></pre></td></tr></table></figure></p><h4 id="一构建词汇表">（一）构建词汇表</h4>在处理文本之前，需要创建一个词汇表——一个包含训练数据集中每个单词的字典。例如，如果我们的训练数据包含各种励志名言，我们的词汇表可能包括“生活”、“平衡”、“自行车”、“前行”等词汇。每个单词都映射到一个唯一的索引。因此，训练数据中所有不重复的单词将组成词汇表。<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><p align="center"><font face="黑体" size=2.>表1 词汇表示例</font></p><div class="center"><table><thead><tr class="header"><th>单词</th><th>a</th><th>ant</th><th>bicycle</th><th>is</th><th>joker</th><th>kite</th><th>life</th><th>like</th><th>riding</th><th>see</th><th>thank</th><th>…</th></tr></thead><tbody></tbody></table></div><h4 id="二分配数字索引">（二）分配数字索引</h4>接下来，我们为词汇表中的每个单词分配一个唯一的数字索引。这样，我们就可以用数字来表示单词了。<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><p align="center"><font face="黑体" size=2.>表2 单词分配索引示例</font></p><div class="center"><table><thead><tr class="header"><th>单词</th><th>a</th><th>ant</th><th>bicycle</th><th>is</th><th>joker</th><th>kite</th><th>life</th><th>like</th><th>riding</th><th>see</th><th>thank</th><th>…</th></tr></thead><tbody><tr class="odd"><td>索引</td><td>3214</td><td>4234</td><td>2342</td><td>423</td><td>34</td><td>5352</td><td>74567</td><td>52345</td><td>5234</td><td>212</td><td>8567</td><td>…</td></tr></tbody></table></div><h4 id="三提取输入单词的索引">（三）提取输入单词的索引</h4>对于输入文本“Life is like riding a bicycle”，我们提取相应的索引如下，<style>.center {  width: auto;  display: table;  margin-left: auto;  margin-right: auto;}</style><p align="center"><font face="黑体" size=2.>表3 提取输入文本中的单词分配索引示例</font></p><div class="center"><table><thead><tr class="header"><th>单词</th><th>a</th><th>bicycle</th><th>is</th><th>life</th><th>like</th><th>riding</th></tr></thead><tbody><tr class="odd"><td>索引</td><td>3214</td><td>2342</td><td>423</td><td>74567</td><td>52345</td><td>5234</td></tr></tbody></table></div><h4 id="四转换成序列">（四）转换成序列</h4><p>这一系列的索引就是输入到Transformer模型中的数据。它作为输入文本的数值表示，使模型能够对其进行处理。</p><p><img src="2025-04-13-14-33-52.png" /></p><h3 id="二词嵌入">二、词嵌入</h3><p>一旦我们有了输入序列的索引，下一步就是将这些索引转换成词嵌入。词嵌入将每个单词表示为固定大小的向量，使得模型更容易捕捉单词之间的语义关系。</p><p>词嵌入是编码单词语义信息的高维向量，相似的单词或经常同时出现的单词具有相似的嵌入。这些向量可以想象成一个多维空间，在这个空间中，由于上下文相似，“bicycle”（自行车）和“ride”（骑行）之间的距离比“bicycle”（自行车）和“cloud”（云）之间的距离更近。嵌入的每个维度都捕捉了某些语言特征，比如一个单词是动词还是实体。 <img src="2025-04-13-14-11-40.png" alt="词life对应的词嵌入" /></p><p>我们序列中的每个词索引都会通过一个嵌入层来生成词嵌入。这个层将每个索引映射到一个实数向量。原始的Transformer论文中使用的嵌入大小为512。 <img src="2025-04-13-15-27-31.png" /></p><p>这样的话经过embedding层之后我们就得到了这样一个嵌入： <img src="2025-04-13-14-12-41.png" /></p><h3 id="三位置嵌入">三、位置嵌入</h3><p>现在我们已经有了词嵌入，接下来需要解决一个关键问题——Transformer天生并不理解单词的顺序。与像LSTM这样的循环模型逐个处理序列中的单词不同，Transformer会同时查看所有单词。虽然这使得它们更快，但也意味着它们缺乏单词出现顺序的信息。</p><p>考虑以下两个句子：</p><p><em>“Life is like riding a bicycle, it requires balance.”（生活就像骑自行车，它需要平衡。）</em></p><p><em>“Life requires balance, like riding a bicycle.”（生活需要平衡，就像骑自行车一样。）</em></p><p>这两个句子包含相同的单词，但结构略有不同，导致意义上有细微差别。为了让Transformer捕捉到这些差异，我们需要添加关于单词顺序的信息——这就是位置嵌入发挥作用的地方。 <img src="2025-04-13-14-16-14.png" /></p><h4 id="一-常见的几种位置编码的思路">（一） 常见的几种位置编码的思路：</h4><ul><li><strong>方法1：基于整数的位置编码</strong><ul><li>一个直接的想法是给每个位置分配一个对应的整数。</li><li>例如，第一个词的嵌入会携带一个全零向量，下一个词则是一个全一向量，依此类推。</li><li>然而，这种方法很快就会暴露出局限性。随着序列长度的增加，分配给后续单词的较大数字可能会压过底层的词嵌入，导致表示发生偏斜。这种不对齐可能会影响模型保持语义一致性的能力，尤其是在较长文本中。 <img src="2025-04-13-14-45-35.png" /></li></ul></li><li><strong>方法2：相对于序列长度的分数位置表示</strong><ul><li>另一种直观的方法是将每个单词的位置表示为总序列长度的一个分数，确保值在0到1之间保持归一化。</li><li>例如，在一个包含四个单词的句子中，位置嵌入可能对应于像0.25、0.5这样的值。</li><li>这一策略虽然看似有效，但却引入了一个重大挑战：相同位置（例如，第二个单词p1）的位置嵌入会因序列长度的不同而变化，从而引入不一致性，这可能会使模型感到困惑并降低性能。为了获得最佳结果，位置值理应独立于序列长度。 <img src="2025-04-13-14-45-52.png" /></li></ul></li><li><strong>方法3：正弦位置嵌入</strong><ul><li>下一种方法利用正弦函数来生成位置嵌入，从而在x轴上创建一条平滑的波浪形曲线来编码单词位置。通过将单词位置映射到正弦波的高度，每个位置都会在一个有限范围内获得一个唯一值，无论序列长度如何。</li><li>这种方法通过标准化位置嵌入值，缓解了之前方法中出现的扭曲风险。</li><li>然而，一个缺点出现在曲线上对称位置的单词上（例如，在可视化环境中用蓝色和紫色等颜色表示）；尽管这些单词的位置不同，但它们产生的位置值却相同，这可能导致潜在的歧义。 <img src="2025-04-13-14-46-14.png" /></li></ul></li><li><strong>方法4：受二进制启发的编码</strong><ul><li>最后，一种创新的视角借鉴了二进制表示原理。在二进制编码中，比特率的变化是可预测的；最低有效位在每个数字间交替变化，下一个较低的位在每两个数字间交替，依此类推。</li><li>将这种概念从二进制位转换为浮点数，可以实现一种紧凑且高效的编码机制，该机制能够在不占用过多计算资源的情况下保持单词位置的唯一性。 <img src="2025-04-13-14-46-27.png" /></li></ul></li></ul><h4 id="二transformer方法使用正弦函数的位置编码">（二）Transformer方法：使用正弦函数的位置编码</h4><p>在Transformer的背景下，通过正弦函数嵌入单词位置提供了一种精细的方法来连续捕获位置信息。该解决方案通过使用交替的正弦和余弦函数，解决了传统位置编码的挑战。这些函数表示出类似于二进制位模式的连续、平滑波形，但在基于浮点数的系统中更加灵活和高效。</p><ul><li><strong>正弦位置编码</strong>：Transformer模型采用正弦和余弦函数生成位置嵌入。对于每个位置pos和维度i，位置嵌入的计算公式为：<ul><li>偶数维度：PE(pos, 2i) = sin(pos / 10000^(2i/d_model))</li><li>奇数维度：PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model)) 其中d_model是模型的嵌入维度。这种编码方式具有周期性，能够处理比训练时更长的序列，同时保持位置信息的一致性。</li></ul></li></ul><p><strong>正弦频率调制</strong></p><p>为了避免位置嵌入的冗余，不同位置使用不同频率的正弦函数，引入了一种微妙但强大的手段来区分序列中即使位置相近的单词。</p><p>根据嵌入向量中的每个位置而变化。在这里，变量i在产生这些变化中起着关键作用。通过在不同的i值下重新计算正弦曲线，在嵌入维度上生成了一系列具有不同频率的曲线，为每个位置pos创建了细微差别的位置嵌入。在这里，d=512，是位置嵌入的维度。</p><h4 id="三将词嵌入和位置嵌入相加得到最终的嵌入向量作为transformer模型的输入">（三）将词嵌入和位置嵌入相加，得到最终的嵌入向量，作为Transformer模型的输入。</h4><ul><li><strong>相加操作</strong>：对于每个单词，将其词嵌入向量与对应位置的位置嵌入向量相加。例如，单词“生活”在句子中的位置为0，其词嵌入向量为E_word，位置嵌入向量为PE(0)，则最终的嵌入向量为E_word + PE(0)。</li><li><strong>模型输入</strong>：经过相加操作后得到的嵌入向量序列，包含了单词的语义信息和位置信息，被送入Transformer模型的后续层进行进一步处理。</li></ul><h4 id="大模型对句子进行编码">大模型对句子进行编码</h4><p>前文介绍的编码方式是 <strong>对句子中的每个词进行单独编码最后汇总成句子向量</strong>，而目前大模型对句子进行编码时，主要分为两种情况：</p><ol type="1"><li><p><strong>对句子中的每个词进行编码</strong>：BERT模型会为句子中的每个词生成一个固定维度的向量。具体维度取决于所使用的BERT模型版本。例如，对于一个包含50个词的句子：</p><ul><li>对于<strong>BERT-Base</strong>，隐藏层维度为<strong>768维</strong>；对于<strong>BERT-Large</strong>，隐藏层维度为<strong>1024维</strong>。使用<strong>BERT-Base</strong>时，每个词的编码维度为<strong>768维</strong>，最终得到一个形状为<strong>[50, 768]</strong>的矩阵；</li><li>使用<strong>BERT-Large</strong>时，每个词的编码维度为<strong>1024维</strong>，最终得到一个形状为<strong>[50, 1024]</strong>的矩阵。</li></ul></li><li><strong>将整个句子编码为一个固定维度的向量</strong>：如果希望将整个句子编码为一个固定维度的向量，BERT模型通常会使用一个特殊的标记（如<code>[CLS]</code>）来表示整个句子的语义信息。<ul><li><code>[CLS]</code>标记的输出维度与模型版本的隐藏层维度一致。对于<strong>BERT-Base</strong>，<code>[CLS]</code>标记的输出维度为<strong>768维</strong>；对于<strong>BERT-Large</strong>，<code>[CLS]</code>标记的输出维度为<strong>1024维</strong>。</li><li>因此，无论句子中有多少个词，最终的句子编码都是一个固定维度的向量，即对于<strong>BERT-Base</strong>，句子编码的维度为<strong>768维</strong>；对于<strong>BERT-Large</strong>，句子编码的维度为<strong>1024维</strong>。</li></ul></li></ol><p>BERT模型在处理句子类型的编码时，会通过以下几种方式来统一维度，无论是句子过短还是过长：</p><ol type="1"><li><strong>句子长度不足最大长度</strong><ul><li>当句子长度不足BERT模型的最大长度限制（通常为512）时，BERT会通过<strong>填充（Padding）</strong>来统一维度：<ul><li>在句子的末尾添加<code>[PAD]</code>标记，直到句子长度达到预设的最大长度。</li><li>这样可以确保所有输入序列的长度一致，便于模型处理。</li></ul></li></ul></li><li><strong>句子长度超过最大长度</strong><ul><li>当句子长度超过BERT模型的最大长度限制（512）时，有以下几种处理方法：<ol type="1"><li><strong>截断（Truncation）</strong><ul><li>直接将句子截断到最大长度（512），丢弃超出部分。</li><li>这种方法简单直接，但可能会丢失一些重要的上下文信息。</li></ul></li><li><strong>滑动窗口（Sliding Window）</strong><ul><li>将长文本分割成多个长度为512的片段，每个片段之间有一定重叠。</li><li>对每个片段分别进行编码，然后将结果合并。</li><li>这种方法可以保留更多的上下文信息，但计算成本较高。</li></ul></li><li><strong>关键片段提取（Key Text Extraction）</strong><ul><li>使用特定的机制（如CogLTX中的MenRecall模块）从长文本中提取与任务相关的关键片段。</li><li>将这些关键片段组合成新的文本，其长度不超过512，然后输入BERT模型。</li><li>这种方法可以有效减少信息丢失，同时降低计算成本。</li></ul></li><li><strong>修改位置编码（Position Embeddings）</strong><ul><li>通过修改BERT的位置编码，使其能够处理更长的文本。</li><li>例如，将位置编码的长度从512扩展到1024，通过拼接或重新初始化等方式实现。</li><li>这种方法需要对BERT模型进行一定的修改，但可以处理更长的文本。</li></ul></li></ol></li></ul></li></ol><p>BERT模型通过填充、截断、滑动窗口、关键片段提取和修改位置编码等方式来处理不同长度的句子，确保输入维度的一致性，同时尽量减少信息丢失并保持计算效率。</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>基于ragas和evalscope实现rag快速评测</title>
    <link href="/2025/04/07/ReadingNotes/rag/rag_eval/"/>
    <url>/2025/04/07/ReadingNotes/rag/rag_eval/</url>
    
    <content type="html"><![CDATA[<hr /><h3 id="ragas-评估工具概述">Ragas 评估工具概述</h3><p>Ragas 是一个用于评估 RAG（Retrieval-Augmented Generation，检索增强生成）应用程序的工具库。它通过提供一系列工具来帮助用户轻松且自信地评估其 RAG 应用程序的性能。</p><p>Ragas 采用了一种新颖的评测数据生成方法。理想的评测数据集应该涵盖实际应用中遇到的各种类型的问题，包括不同难度等级的问题。然而，默认情况下，大语言模型（LLMs）通常不擅长创建多样化的样本，因为它们往往会遵循常见的路径。受到 Evol-Instruct 等工作的启发，Ragas 通过采用进化生成范式来实现这一目标。在这个过程中，具有不同特征的问题（如推理、条件、多个上下文等）会根据提供的文档集被系统地构建。这种方法确保了对管道中各个组件性能的全面覆盖，从而使评测过程更加稳健。</p><p>Ragas 的官网 <a href="https://docs.ragas.io/" class="uri">https://docs.ragas.io/</a> 介绍了如何通过大模型 API 接口初始化评测端模型，以实现评测指标的计算。然而，这种方式可能会受到网络连接等因素的影响，从而限制本地应用的效果。</p><h3 id="在本地部署-ragas-服务">在本地部署 Ragas 服务</h3><p>为了克服网络连接问题并提升本地应用的性能，可以通过 <a href="https://evalscope.readthedocs.io/zh-cn/latest/user_guides/backend/rageval_backend/ragas.html">EvalScope</a> 项目结合 <a href="https://vllm.hyper.ai/docs/getting-started/quickstart/">vLLM</a> 来实现本地部署。</p><h4 id="使用-vllm-构建本地-api-服务器">使用 vLLM 构建本地 API 服务器</h4><p>vLLM 是一个高性能的推理引擎，可以在本地为大语言模型构建 API 服务器。通过 vLLM，用户可以快速部署本地 Ragas 服务，从而避免网络连接问题对评估过程的影响。</p><p>以下是使用 vLLM 构建本地 API 服务器的步骤：</p><ol type="1"><li><p><strong>安装 vLLM</strong>： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install vllm<br></code></pre></td></tr></table></figure></p></li><li><p><strong>启动 vLLM 服务器</strong>： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">vllm serve facebook/opt-125m<br></code></pre></td></tr></table></figure> 默认情况下，服务器会在 <code>http://localhost:8000</code> 启动。可以通过 <code>--host</code> 和 <code>--port</code> 参数指定其他地址。</p></li><li><p><strong>使用 OpenAI API 兼容模式</strong>： vLLM 服务器支持 OpenAI API 协议，可以直接替代 OpenAI API。可以使用 <code>curl</code> 或 Python 客户端进行查询。例如： <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl http://localhost:8000/v1/completions \<br>    -H <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>    -d <span class="hljs-string">&#x27;&#123;</span><br><span class="hljs-string">        &quot;model&quot;: &quot;facebook/opt-125m&quot;,</span><br><span class="hljs-string">        &quot;prompt&quot;: &quot;San Francisco is a&quot;,</span><br><span class="hljs-string">        &quot;max_tokens&quot;: 7,</span><br><span class="hljs-string">        &quot;temperature&quot;: 0</span><br><span class="hljs-string">    &#125;&#x27;</span><br></code></pre></td></tr></table></figure></p></li><li><p><strong>在 EvalScope 中使用本地 vLLM 服务</strong>： 在 EvalScope 的配置中，将评测模型的 API 基础地址设置为本地 vLLM 服务器的地址。例如： <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs python">eval_task_cfg = &#123;<br>    <span class="hljs-string">&quot;eval_backend&quot;</span>: <span class="hljs-string">&quot;RAGEval&quot;</span>,<br>    <span class="hljs-string">&quot;eval_config&quot;</span>: &#123;<br>        <span class="hljs-string">&quot;tool&quot;</span>: <span class="hljs-string">&quot;RAGAS&quot;</span>,<br>        <span class="hljs-string">&quot;eval&quot;</span>: &#123;<br>            <span class="hljs-string">&quot;testset_file&quot;</span>: <span class="hljs-string">&quot;outputs/testset_with_answer.json&quot;</span>,<br>            <span class="hljs-string">&quot;critic_llm&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;model_name&quot;</span>: <span class="hljs-string">&quot;facebook/opt-125m&quot;</span>,<br>                <span class="hljs-string">&quot;api_base&quot;</span>: <span class="hljs-string">&quot;http://localhost:8000/v1&quot;</span>,<br>                <span class="hljs-string">&quot;api_key&quot;</span>: <span class="hljs-string">&quot;EMPTY&quot;</span>,<br>            &#125;,<br>            <span class="hljs-string">&quot;embeddings&quot;</span>: &#123;<br>                <span class="hljs-string">&quot;model_name_or_path&quot;</span>: <span class="hljs-string">&quot;AI-ModelScope/m3e-base&quot;</span>,<br>            &#125;,<br>            <span class="hljs-string">&quot;metrics&quot;</span>: [<br>                <span class="hljs-string">&quot;Faithfulness&quot;</span>,<br>                <span class="hljs-string">&quot;AnswerRelevancy&quot;</span>,<br>                <span class="hljs-string">&quot;ContextPrecision&quot;</span>,<br>                <span class="hljs-string">&quot;AnswerCorrectness&quot;</span>,<br>            ],<br>            <span class="hljs-string">&quot;language&quot;</span>: <span class="hljs-string">&quot;chinese&quot;</span><br>        &#125;,<br>    &#125;,<br>&#125;<br></code></pre></td></tr></table></figure></p></li></ol>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>M3-Embedding Multi-Linguality, Multi-Functionality, Multi-Granularity Text Embeddings Through Self-Knowledge Distillation</title>
    <link href="/2025/03/13/ReadingNotes/rag/M3-Embedding/"/>
    <url>/2025/03/13/ReadingNotes/rag/M3-Embedding/</url>
    
    <content type="html"><![CDATA[<h2 id="研究背景">研究背景</h2><p>这篇文章要解决的问题是如何设计一种多语言、多功能、多粒度的文本嵌入模型，以支持超过100种工作语言的语义检索，并能同时完成<mark>密集检索、多向量检索和稀疏检索</mark>等多种检索功能。</p><h2 id="研究方法">研究方法</h2><h3 id="混合检索">混合检索</h3><p>M3-Embedding统一了文本嵌入模型的常见检索功能，包括密集检索、词汇（稀疏）检索和多向量检索。这些功能不仅可以单独工作，还可以协同工作以获得更强的检索质量。</p><h4 id="密集检索dense-retrieval.">密集检索（Dense retrieval.）</h4><ul><li>输入query <span class="math inline"><em>q</em></span> 将转换为基于文本编码器的隐藏状态 <span class="math inline"><strong>H</strong><sub><strong>q</strong></sub></span>。使用特殊标记 “[CLS]” 的规范化隐藏状态来表示query：<span class="math inline"><em>e</em><sub><em>q</em></sub> = norm(<strong>H</strong><sub><strong>q</strong></sub>[0])</span></li><li><p>passage的嵌入 <span class="math inline"><em>p</em></span> 为 <span class="math inline"><em>e</em><sub><em>p</em></sub> = norm(<strong>H</strong><sub><strong>p</strong></sub>[0])</span>。</p></li><li><p>因此，query和passage之间的相关性分数由两个嵌入和 <span class="math inline"><em>e</em><sub><em>q</em></sub><em>e</em><sub><em>p</em></sub></span>：<span class="math inline"><em>s</em><sub>dense</sub> ← ⟨<em>e</em><sub><em>p</em></sub>, <em>e</em><sub><em>q</em></sub>⟩</span> 之间的内积来衡量。</p></li></ul><h4 id="词汇检索lexical-retrieval.">词汇检索（Lexical Retrieval. ）</h4><ul><li>对于query中的每个token <span class="math inline"><em>t</em></span>，其权重的计算公式为</li></ul><p><br /><span class="math display">$$w_{q_t} \leftarrow\text{Relu}(\mathbf{W}_{\text{lex}}^T \mathbf{H_q}[i])\\$$</span><br /></p><ul><li>其中 <span class="math inline"><strong>W</strong><sub>lex</sub> ∈ ℝ<sup><em>d</em> × 1</sup></span> 是将隐藏状态映射到浮点数的矩阵。</li><li>如果某个token <span class="math inline"><em>t</em></span> 在query中多次出现，只保留其最大权重。并使用相同的方法来计算passage中每个token的权重。</li><li>因此query和passage之间的相关性分数是通过query和passage中共存token（表示为 <span class="math inline"><em>q</em> ∩ <em>p</em></span>）的联合重要性来计算的：</li><li><br /><span class="math display">$$s_{\text{lex}} \leftarrow \sum_{t \in q \cap p}(w_{q_t} * w_{p_t})\\$$</span><br /></li></ul><h4 id="多向量检索-multi-vector-retrieval.">多向量检索 (Multi-Vector Retrieval. )</h4><ul><li>作为密集检索的扩展，多向量检索利用整个输出嵌入来表示query和passage：</li></ul><p><br /><span class="math display">$$E_q = \text{norm}(\mathbf{W}_{\text{mul}}^T \mathbf{H_q})\\ $$</span><br /></p><p><br /><span class="math display">$$E_p = \text{norm}(\mathbf{W}_{\text{mul}}^T \mathbf{H_p})\\$$</span><br /></p><ul><li><p>其中 <span class="math inline"><strong>W</strong><sub>mul</sub> ∈ ℝ<sup><em>d</em> × <em>d</em></sup></span> 是可学习的投影矩阵。</p></li><li>使用后期交互来计算细粒度的相关性分数： <br /><span class="math display">$$s_{\text{mul}} \leftarrow \frac{1}{N} \sum_{i=1}^N \max_{j=1}^M E_q[i] \cdot E_p^T[j]\\$$</span><br /></li><li><p><span class="math inline"><em>N</em></span> 和 <span class="math inline"><em>M</em></span> 是query和passage的长度。</p></li></ul><p>每种方法都可以单独检索候选结果（多向量方法由于成本高，可以免于此步骤）。然后，根据集成的相关性分数对最终检索结果进行重新排名：</p><p><br /><span class="math display">$$S_{\text{rank}} \leftarrow w_1 \cdot S_{\text{dense}} + w_2 \cdot S_{\text{lex}} + w_3 \cdot S_{\text{mul}}\\$$</span><br /></p><h3 id="自我认识蒸馏self-knowledge-distillation">自我认识蒸馏(Self-Knowledge Distillation)</h3><h4 id="损失函数">损失函数</h4><p>嵌入模型经过训练以区分阳性样本和阴性样本。对于每种检索方法，与负样本相比，应为查询的正样本分配更高的分数。因此，进行训练过程以最小化 InfoNCE 损失，其一般形式由以下损失函数表示：</p><p><img src="2025-04-14-15-01-21.png" /></p><p>这里，<span class="math inline"><em>p</em><sup>*</sup></span> 和 <span class="math inline"><em>p</em>′</span> 代表查询 <span class="math inline"><em>q</em></span> 的正样本和负样本</p><p><span class="math inline"><em>s</em>( ⋅ )</span> 是 <span class="math inline"><em>s</em><sub>dense</sub>( ⋅ )</span>,<span class="math inline"><em>s</em><sub>lex</sub>( ⋅ )</span>,<span class="math inline"><em>s</em><sub>mul</sub>( ⋅ )</span> 中的任何函数。</p><ul><li>不同检索方法的训练目标可能与各自的方法相互冲突。因此，原生多目标训练可能不利于嵌入的质量。为了促进多个检索函数的优化，作者建议在自我知识蒸馏之上统一训练过程。在最简单的形式中，积分可以是不同预测分数的加权和：</li></ul><p><br /><span class="math display">$$S_{\text{inter}} \leftarrow w_1 \cdot S_{\text{dense}} + w_2 \cdot S_{\text{lex}} + w_3 \cdot S_{\text{mul}}\\$$</span><br /></p><ul><li>使用积分分数 <span class="math inline"><em>S</em><sub><em>i</em><em>n</em><em>t</em><em>e</em><em>r</em></sub></span>作为老师，于是其中每种检索方法的损失函数被修改为:</li></ul><p><img src="2025-04-14-15-02-08.png" /> - 这里，<span class="math inline"><em>p</em>( ⋅ )</span> 是 softmax 激活；<span class="math inline"><em>s</em><sub>*</sub></span> 是 <span class="math inline"><em>s</em><sub>dense</sub></span>、<span class="math inline"><em>s</em><sub>lex</sub></span> 和 <span class="math inline"><em>s</em><sub>mul</sub></span> 中的任何成员。我们进一步整合并归一化修改后的损失函数： <img src="2025-04-14-15-02-26.png" /></p><p>最后，用 <span class="math inline">ℒ</span> 和的 <span class="math inline">ℒ′</span> 线性组合推导出自我知识蒸馏的最终损失函数： <br /><span class="math display">$$\mathcal{L}_{\text{final}} \leftarrow \left( \mathcal{L} + \mathcal{L}' \right) / 2\\$$</span><br /></p><h4 id="训练过程">训练过程</h4><p>训练过程包括一个<strong>多阶段工作流</strong>（如图所示）。首先，文本编码器（XLM-RoBERTa模型）使用大量无监督数据进行预训练，其中仅以基本形式的对比学习训练密集检索。</p><p>在第二阶段应用自知识蒸馏，其中嵌入模型被微调以建立三个检索功能。<span class="math inline"><strong>W</strong><sub>lex</sub></span>的随机初始化导致<span class="math inline"><em>s</em><sub>lex</sub></span>准确性差和训练开始时的<span class="math inline">ℒ<sub>lex</sub></span>高。</p><p><img src="/images/m3-embedding训练过程.png" /></p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>hexo搭建博客实现多端同步</title>
    <link href="/2025/02/25/essays/Hexo/hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/"/>
    <url>/2025/02/25/essays/Hexo/hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E5%AE%9E%E7%8E%B0%E5%A4%9A%E7%AB%AF%E5%90%8C%E6%AD%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="基于hexogithub实现博客撰写的多端同步功能">基于hexo+github实现博客撰写的多端同步功能</h1><p>hexo 本身自带的同步功能<code>hexo d</code>上传的只是网页部署文件，未上传网页源文件，所以如果我们要在另一台设备上对博客进行修改的话就会遇到困难。我们可以在在github的blog仓库新建一个分支，存储源文件，然后在不同设备间同步源文件。这样就可以实现博客在不同设备上的同步了。</p><h2 id="github对应的仓库新建分支">github对应的仓库新建分支</h2><p>首先你需要在你博客对应的github仓库(比如我的就是<code>https://github.com/yangyihui2020/yangyihui2020.github.io)</code>新建分支<code>hexo</code>。</p><h2 id="在已有博客文件的旧设备上执行的操作">在已有博客文件的旧设备上执行的操作 ：</h2><p>然后在本地任意目录下执行 <code>git clone</code>。并切换到对应分支： <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git clone git@github<span class="hljs-selector-class">.com</span>:yangyihui2020/yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.git</span><br>cd yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><br>git <span class="hljs-selector-tag">switch</span> hexo<br></code></pre></td></tr></table></figure></p><p>然后删除掉仓库目录（比如我的就是<code>yangyihui2020.github.io</code>)下除去.git之外的所有文件，并将原博客目录下的所有文件复制到该目录下。</p><p>然后上传到hexo分支</p><figure class="highlight armasm"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs armasm"><span class="hljs-symbol">git</span> <span class="hljs-keyword">add</span> .<br><span class="hljs-symbol">git</span> commit -m <span class="hljs-string">&quot;新建hexo分支&quot;</span><br><span class="hljs-symbol">git</span> <span class="hljs-keyword">push</span> <br></code></pre></td></tr></table></figure><h2 id="在新设备上执行的操作">在新设备上执行的操作 ：</h2><p>在新设备，你需要提前配置好hexo所需要的环境。可以参考<a href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a> 。</p><p>然后在任意目录下新建一个目录<code>blogs</code>(这个名字随意),进入该目录执行<code>hexo init</code>。 然后清空该目录的文件，并执行<code>git clone</code>并切换到对应的分支: <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs stylus">git clone git@github<span class="hljs-selector-class">.com</span>:yangyihui2020/yangyihui2020<span class="hljs-selector-class">.github</span><span class="hljs-selector-class">.io</span><span class="hljs-selector-class">.git</span><br>git <span class="hljs-selector-tag">switch</span> hexo<br></code></pre></td></tr></table></figure></p><p>然后你就可以在不同设备上实现hexo博客的源文件共享了。 <div class="note note-info">            <p>注意，每次写博客之前最好执行<code>git pull</code>，上传网页后同时执行一下<code>git push</code>来保持文件的同步</p>          </div></p><h2 id="可能会遇到的问题">可能会遇到的问题</h2><div class="note note-danger">            <p>在这个过程中可能会遇到<code>hexo g</code>等命令不起作用的情况，hexo提示的命令也变少了.</p>          </div><div class="note note-info">            <p>这个时候你就要观察你执行命令的目录是否是你博客真正对应的目录。 比如我执行完上述操作后，我的博客目录应该是yangyihui2020.github.io，而不是blogs。 你必须要在博客对应目录下执行对应操作才行。</p>          </div>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</title>
    <link href="/2025/02/24/ReadingNotes/rag/Retrieval-Augmented%20Generation%20for%20%20Knowledge-Intensive%20NLP%20Tasks/"/>
    <url>/2025/02/24/ReadingNotes/rag/Retrieval-Augmented%20Generation%20for%20%20Knowledge-Intensive%20NLP%20Tasks/</url>
    
    <content type="html"><![CDATA[<h1 id="rag-检索增强生成技术背景介绍">RAG 检索增强生成技术背景介绍</h1><p>RAG（Retrieval-Augmented Generation，检索增强生成） 是一种结合了信息检索技术与语言生成模型的人工智能技术。该技术通过从外部知识库中检索相关信息，并将其作为提示（Prompt）输入给大型语言模型（LLMs），以增强模型处理知识密集型任务的能力，如问答、文本摘要、内容生成等。RAG模型由Facebook AI Research（FAIR）团队于2020年首次提出，并迅速成为大模型应用中的热门方案。(这篇论文可以说是RAG技术的开山之作)</p><p><img src="/images/rag.jpg" /></p><p>RAG一般有3个步骤： 1. 检索：检索是RAG流程的第一步，从预先建立的知识库中检索与问题相关的信息。这一步的目的是为后续的生成过程提供有用的上下文信息和知识支撑。</p><ol start="2" type="1"><li><p>增强：RAG中增强是将检索到的信息用作生成模型（即大语言模型）的上下文输入，以增强模型对特定问题的理解和回答能力。这一步的目的是将外部知识融入生成过程中，使生成的文本内容更加丰富、准确和符合用户需求。通过增强步骤，LLM模型能够充分利用外部知识库中的信息。</p></li><li><p>生成：生成是RAG流程的最后一步。这一步的目的是结合LLM生成符合用户需求的回答。生成器会利用检索到的信息作为上下文输入，并结合大语言模型来生成文本内容。</p></li></ol><h1 id="rag-retrieval-augmented-generation-for-knowledge-intensive-nlp-tasks">RAG Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</h1><p><a href="https://arxiv.org/abs/2005.11401">文章链接</a></p><h2 id="研究背景">研究背景</h2><p>这篇文章的研究背景是大型预训练语言模型虽然能够在下游NLP任务中存储事实性知识并取得优异表现，但在访问和精确操作知识方面仍然有限。因此，在知识密集型任务中，这些模型的表现落后于特定任务的架构。此外，提供决策的可追溯性和更新世界知识仍然是开放的研究问题。</p><p>文章着眼于此，提出的RAG模型通过结合预训练的参数化记忆和非参数化记忆，在知识密集型NLP任务中取得了显著的性能提升。 ## 研究方法</p><p>这篇论文提出了两种RAG模型：RAG-Sequence和RAG-Token，用于解决知识密集型任务中的生成问题：</p><ol type="1"><li>​<strong>RAG-Sequence模型:</strong>​ 该模型使用相同的检索文档来生成整个序列。它将检索到的文档视为一个单一的潜在变量，并通过top-K近似来边缘化以获得seq2seq概率。 <img src="/images/RAG-Sequence-Model.png" alt="RAG-Sequence-Model相应公式" /></li><li>​<strong>RAG-Token模型:</strong>​ 该模型为每个目标标记抽取不同的潜在文档，并相应地进行边缘化。这允许生成器在生成答案时从多个文档中选择内容。具体来说，使用检索器检索前 K 个文档，然后生成器为每个文档的下一个输出标记生成一个分布，然后边缘化，并使用以下输出标记重复该过程。 <img src="/images/RAG-Token-Model.png" alt="alt text" /></li></ol><p>检索器：使用DPR（Dense Passage Retriever）作为检索组件，采用双向编码器架构，通过最大内积搜索（MIPS）问题近似求解top-K文档。 <img src="/images/Retriever.png" alt="alt text" /> 生成器：使用BART-large作为生成器组件，通过连接输入和检索内容来生成输出。</p><h2 id="实验">实验</h2><p>实验采用了多个知识密集型NLP任务的数据集，包括自然问题（NQ）、TriviaQA（TQA）、WebQuestions（WQ）、CuratedTrec（CT）、MS-MARCO、Jeopardy问题生成和FEVER。</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>THE power of noise</title>
    <link href="/2025/02/24/ReadingNotes/rag/The%20Power%20of%20Noise-Redefining%20Retrieval%20for%20RAG%20Systems/"/>
    <url>/2025/02/24/ReadingNotes/rag/The%20Power%20of%20Noise-Redefining%20Retrieval%20for%20RAG%20Systems/</url>
    
    <content type="html"><![CDATA[<p>ddgf</p>]]></content>
    
    
    <categories>
      
      <category>ReadingNotes</category>
      
      <category>rag</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>用hexo+fluid配置个人博客</title>
    <link href="/2025/02/22/essays/Hexo/%E7%94%A8hexo+fluid%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2025/02/22/essays/Hexo/%E7%94%A8hexo+fluid%E9%85%8D%E7%BD%AE%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="环境准备">环境准备</h1><p>在开始之前，你需要先参考<a href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a>进行安装、建站。</p><h2 id="然后设置你的主题为fluid">然后设置你的主题为fluid：</h2><ul><li><p>进入博客目录执行命令：<code>npm install --save hexo-theme-fluid</code></p></li><li><p>修改 Hexo 博客目录下<code>_config.yml</code>中的对应参数：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">theme:</span> <span class="hljs-string">fluid</span>  <span class="hljs-comment"># 指定主题为fluid</span><br></code></pre></td></tr></table></figure><h1 id="开始新文档创建">开始新文档创建</h1><h2 id="创建关于页">创建<code>关于页</code></h2><ul><li><p>在博客目录下执行命令：<code>hexo new page about</code></p></li><li><p>创建成功后修改 <code>/source/about/index.md</code>，在其中添加 <code>layout</code> 属性。</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">标题</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">about</span><br><span class="hljs-meta">---</span><br><span class="hljs-meta"></span><br><span class="hljs-string">这里写关于页的正文，支持</span> <span class="hljs-string">Markdown,</span> <span class="hljs-string">HTML</span><br></code></pre></td></tr></table></figure><div class="note note-info">            <p>根据官方文档，<code>layout: about</code> 必须存在，并且不能修改成其他值，否则不会显示头像等样式。</p><p>一般<code>关于页</code>可以介绍你的个人资料</p>          </div><h2 id="创建新的文章并为其归类这里的做法为个人偏好仅供参考">创建新的文章并为其归类。（这里的做法为个人偏好，仅供参考）</h2><p>我现在需要写一篇名为<code>用hexo+fluid配置个人博客</code>的文章，我想给其分类到<code>随笔</code>下的<code>Hexo</code>小类中，这里我就用到了hexo的二级导航功能。具体做法如下：</p><h3 id="生成分类页并添加tpye属性">生成“分类”页并添加tpye属性</h3><ul><li><p>进入博客所在文件夹。执行命令：<code>hexo new page categories</code></p></li><li><p>修改博客目录下的<code>source/categories/index.md</code>为：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">categories</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-22 19:55:44</span><br><span class="hljs-attr">layout:</span> <span class="hljs-string">categories</span> <span class="hljs-comment">#添加这一行代码到原md文件中</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><h3 id="创建随笔hexo类别">创建<code>随笔\Hexo</code>类别：</h3><ul><li><p>在 <code>source/categories</code> 文件夹下创建一个名为 <code>essay</code> 的文件夹,再在<code>essay</code>文件夹内新建<code>Hexo</code>文件夹</p></li><li><p>在<code>source/categories/essay/和</code> <code>source/categories/essay/Hexo</code> 文件夹下均创建一个名为 <code>index.md</code> 的文件，内容如下</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-22 19:57:44</span><br><span class="hljs-attr">type:</span> <span class="hljs-string">categories</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><ul><li>修改主题目录下的<code>_config.yaml</code>文件中的menu属性，它将影响到网页中的菜单栏，修改为：</li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">menu:</span><br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;home&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont icon-home-fill&quot;</span> &#125;<br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;随笔&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/categories/essay/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont book icon-book&quot;</span>,<br>    <span class="hljs-attr">submenu:</span> [&#123;<span class="hljs-attr">key:</span> <span class="hljs-string">&#x27;Hexo用户笔记&#x27;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&#x27;/categories/essay/Hexo/&#x27;</span>&#125;,],&#125;<br>  <span class="hljs-comment"># 设置你的多级目录以及设置key的值作为菜单栏中展示的分类名</span><br>  <span class="hljs-bullet">-</span> &#123; <span class="hljs-attr">key:</span> <span class="hljs-string">&quot;about&quot;</span>, <span class="hljs-attr">link:</span> <span class="hljs-string">&quot;/about/&quot;</span>, <span class="hljs-attr">icon:</span> <span class="hljs-string">&quot;iconfont icon-user-fill&quot;</span>,&#125;<br>  <span class="hljs-comment">#- &#123; key: &quot;archive&quot;, link: &quot;/archives/&quot;, icon: &quot;iconfont icon-archive-fill&quot; &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;categories&quot;, link: &quot;/categories/&quot;, icon: &quot;iconfont icon-category-fill&quot;, &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;tag&quot;, link: &quot;/tags/&quot;, icon: &quot;iconfont icon-tags-fill&quot; &#125;</span><br>  <span class="hljs-comment">#- &#123; key: &quot;links&quot;, link: &quot;/links/&quot;, icon: &quot;iconfont icon-link-fill&quot; &#125;</span><br></code></pre></td></tr></table></figure><div class="note note-info">            <p>注意，我这里注释掉了不必要的菜单栏</p>          </div><h3 id="创建新的文章并归类">创建新的文章并归类:</h3><ul><li><p>在<code>source\_posts</code>目录下新建<code>essays\Hexo</code>目录结构</p></li><li><p>执行<code>hexo new 用hexo+fluid配置个人博客 -p essays\Hexo\用hexo+fluid配置个人博客</code></p></li><li><p>修改<code>source\_posts\essays\Hexo\用hexo+fluid配置个人博客.md</code>中的内容为：</p></li></ul><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-meta">---</span><br><span class="hljs-attr">title:</span> <span class="hljs-string">用hexo+fluid配置个人博客</span><br><span class="hljs-attr">date:</span> <span class="hljs-number">2025-02-23 14:36:55</span><br><span class="hljs-attr">tags:</span><br><span class="hljs-attr">categories:</span> [<span class="hljs-string">essay</span>,<span class="hljs-string">Hexo</span>] <span class="hljs-comment">#加上这一栏即可</span><br><span class="hljs-meta">---</span><br></code></pre></td></tr></table></figure><p>执行完上述一系列操作之后，你将得到这样一个界面：</p><p><img src="/images/image-20250223144908444.jpg" /></p><p>然后你就可以编辑<code>用hexo+fluid配置个人博客.md</code>中的内容作为你的第一篇博客了。</p>]]></content>
    
    
    <categories>
      
      <category>essays</category>
      
      <category>Hexo</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
